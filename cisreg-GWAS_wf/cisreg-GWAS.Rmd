---
title: "Detection of  regulatory SNPs in GWAS studies"
author: "Yvon Mbouamboua, Pascal Rihet, Thi-Thuy-Nga Nguyen, Andrew Parton, Aziz Khan & Jacques van Helden "
date: '`r Sys.Date()`'
output:
  html_document:
    code_folding: hide
    self_contained: no
    fig_caption: yes
    highlight: zenburn
    theme: cerulean
    toc: yes
    toc_depth: 3
    toc_float: yes
  ioslides_presentation:
    colortheme: dolphin
    fig_caption: yes
    fig_height: 6
    fig_width: 7
    fonttheme: structurebold
    highlight: tango
    incremental: no
    keep_md: no
    smaller: yes
    theme: cerulean
    toc: yes
    widescreen: yes
  pdf_document:
    fig_caption: yes
    highlight: zenburn
    toc: yes
    toc_depth: 3
  slidy_presentation:
    self_contained: no
    fig_caption: yes
    fig_height: 6
    fig_width: 7
    highlight: tango
    incremental: no
    keep_md: no
    smaller: yes
    theme: cerulean
    toc: yes
    toc_float: yes
    widescreen: yes
  beamer_presentation:
    colortheme: dolphin
    fig_caption: yes
    fig_height: 6
    fig_width: 7
    fonttheme: structurebold
    highlight: tango
    incremental: no
    keep_tex: no
    slide_level: 2
    theme: Montpellier
    toc: yes
  word_document:
    toc: yes
    toc_depth: 3
font-import: http://fonts.googleapis.com/css ?family=Risque
font-family: Garamond
subtitle: Disease 
address: TAGC lab, Aix-Marseille Université, France
transition: linear
editor_options: 
  chunk_output_type: console
bibliography: 
    bibliography.bib
csl:
    biomed-central.csl
---


```{r start_time}
## Start time 
#start.time <- Sys.time()

ptm <- proc.time()
```


```{r setup, include=FALSE, size="huge"}
message("Loading knitr library")
if (!require("knitr", quietly = TRUE)) {
  message("Installing knitr library")
  install.packages("knitr", dependencies = TRUE)
}
require(knitr)

## Default parameters for displaying the slides
knitr::opts_chunk$set(
  echo = TRUE, 
  eval = TRUE, 
  fig.width = 7, 
  fig.height = 5, 
  fig.align = "center", 
#  fig.path = paste(sep = "", "figures/", parameters$query, "_"),
  size = "tiny", 
  warning = FALSE, 
  results = TRUE, 
  message = FALSE, 
  comment = "")

## Load custom functions
#source("R/bed_to_granges.R")


```

  
```{r parameters, echo=FALSE}

## Define user-specified parameters for the analyses
## Parameters
parameters <- list(
  working.dir = getwd(),
  output.dir = "~/cisreg-GWAS_results",
  query =  "EFO_0001068", # malaria
  # query = "EFO_0001360", # type ii diabetes mellitus
  #query = "HP_0100806", # sepsis
  #query = "EFO_0000249", # Alzheimer's disease
  #query =  "EFO_0008407", # tuberculosis
  ld.pop.prefix = "1000GENOMES:phase_3:",
  population = "AFR",
  r2 = 0.8,
  ld.distance = 200,
  max.ld.per.snp = 500, # ignore LDs for a given tag SNP if there are more too many of them
  include.LD = "AFR", # additional SNPs in LD with Lead SNPs in XGR package
  update.flowcharts = TRUE, # Update the flowcharts with graphviz dot
  flowchart.formats = c("pdf", "png"), # List of formats to generate
  flowchart.format = "pdf", # Format for insertion in the report,
  force.download = FALSE, # if TRUE, files are downloaded even if already present
  #ensemblmart = useMart(biomart = "ENSEMBL_MART_ENSEMBL", dataset = "hsapiens_gene_ensembl"),
  RsatRestUrl = "http://rsat-tagc.univ-mrs.fr/rsat/rest/",
  #RsatRestUrl = "http://rsat-tagc.univ-mrs.fr/rsat/rest.wsgi/",
  #RsatRestUrl = "http://134.158.247.7/rsat/rest/",
  motifDB.URL = "http://jaspar.genereg.net/download/CORE/JASPAR2018_CORE_vertebrates_non-redundant_pfms_transfac.txt",
  remapUrl=  "http://pedagogix-tagc.univ-mrs.fr/remap/download/remap2018/hg38/MACS/remap2018_all_macs2_hg38_v1_2.bed.gz"
)


fig.nb <- 0 ## Initialize figure counter

message("\tWorking directory: ", parameters$working.dir)


## Define a data dir for the data downloaded from other sources
parameters$data.dir = file.path(parameters$output.dir, "data")
message("Data directory\t", parameters$data.dir)
dir.create(parameters$data.dir, showWarnings = FALSE, recursive = TRUE)

## Define result directory for the current EFO 
## by concatenating the output dir and the query ID
parameters$result.dir = file.path(parameters$output.dir, parameters$query)
message("Result directory\t", parameters$result.dir)
dir.create(parameters$result.dir, showWarnings = FALSE, recursive = TRUE)

parameters$figure.dir = file.path(parameters$result.dir, "figures")
message("Result directory\t", parameters$figure.dir)
dir.create(parameters$figure.dir, showWarnings = FALSE, recursive = TRUE)

knitr::opts_chunk$set(fig.path = paste(
  sep = "", parameters$figure.dir, parameters$query, "_"))


## Initialise a vector to summarize the results
workflowSummary <- vector()


```



```{r libraries, include=FALSE,  eval=TRUE, echo=FALSE, warning=FALSE}
message("Loading required libraries")
cran.libraries.to.install <- 
  c("dplyr",   
    "devtools",
    "ggplot2", 
    "gridExtra",
    "cowplot",
    "scales",
    "tidyr",
    "VSE",
    "DiagrammeR",
    "VennDiagram",
    "jsonlite",
    "httr",
    "xml2",
    "RCurl",
    "data.table",
    "gProfileR",
    "DOSE"
 
  )     

bioconductor.libraries.to.install <- c(
  "biomaRt",
  "GenomicRanges",
  "ChIPpeakAnno",
  "ChIPseeker",
  "TxDb.Hsapiens.UCSC.hg38.knownGene",
  "ReactomePA",
  #"rGREAT",
  "XGR",
  #"FunciSNP",
  "TissueEnrich",
  "grImport2"

)

message("Loading CRAN libraries")
for (lib in cran.libraries.to.install) {
  if (require(lib, character.only = TRUE, quietly = TRUE)) {
    message("\tLoaded library\t", lib)
  } else {
    message("Installing CRAN library\t", lib)
    install.packages(lib, dependencies = TRUE)
  }
  require(lib, character.only = TRUE, quietly = TRUE)
}

message("Loading Bioconductor libraries")
for (lib in bioconductor.libraries.to.install) {
  if (!require(lib, character.only = TRUE, quietly = TRUE)) {
    #   message("\tLoaded library\t", lib)
    # } else {
    message("Installing Bioconductor library\t", lib)
    if (!("BiocManager" %in% rownames(installed.packages()))) {
      install.packages("BiocManager")
    } 
    
        BiocManager::install(lib, dependencies = TRUE, ask = FALSE)
    if (!require(lib, character.only = TRUE, quietly = TRUE)) {
      stop("Could not install and load package ", lib)
    }
  }
#   require(lib, character.only = TRUE, quietly = TRUE)
}

## For github libraries we need to know the account for each package -> we encode this as a named vector
github.libraries.to.install <- c("ReMapEnrich" = "remap-cisreg")
message("Loading github libraries")
for (lib in names(github.libraries.to.install)) {
  if (require(lib, character.only = TRUE, quietly = TRUE)) {
    message("\tLoaded library\t", lib)
  } else {
    library(devtools)
    message("Installing github library\t", lib)
    github.path <- paste(sep = "/", github.libraries.to.install[lib], lib)
    install_github(github.path, dependencies = TRUE)
    #    install_github(github.path, dependencies = TRUE, force = TRUE)
  }
  require(lib, character.only = TRUE, quietly = TRUE)
}

```



```{r output_directories}
message("Creating output directories")

# Result directory (export result tables)
result.dirs <- c(TagSNPs = "TagSNPs",
                 Ensembl = "Ensembl",
                 SOIs = "SOIs",
                 ReMap = "ReMap",
                 RSAT = "RSAT",
                 JASPAR = "JASPAR",
                 rSNPs = "rSNPs")
result.dir.path <- file.path(parameters$result.dir, result.dirs)
names(result.dir.path) <- names(result.dirs) ## entry names were lost with the file.paths

for (dir in c(parameters$result.dir, result.dir.path)) {
  message("\t", dir)
  dir.create(dir, showWarnings = FALSE, recursive = TRUE)
}

## Prepare a table for the output files
outfiles <- data.frame()

```



```{r disease_of_interest}
## Identify the disease based on the EFO ID
message("Identifying the disease of interest")
diseaseURL <- paste(sep = "/", 
                    "http://www.ebi.ac.uk/gwas/rest/api/efoTraits", 
                    parameters$query)

GWASstudiesRestOutput <- fromJSON(
  diseaseURL, 
  content_type("application/json"), 
  simplifyDataFrame = FALSE)


parameters$trait <- GWASstudiesRestOutput$trait

## Generate a table displaying the parameters for the report
kable(t(as.data.frame(parameters))[,1], 
      col.names = c("Parameter value"))

```



## Introduction

This report summarises the results of **cisreg-GWAS**, an automatic workflow to predict the impact of genetic variations on cis-regulation, based on the integration of complementary data types. 

The **cisreg-GWAS** makes multi analyses automatic by first constructing a HTTP POST request according to user's input and retrieving results from the web server afterwards, in order:

1. Genome-Wise Association Studies (GWAS), obtained from [**GWAS catalog**](https://www.ebi.ac.uk/gwas/)
2. Linkage desequilibrium data, from [**Ensembl**](https://www.ensembl.org/Homo_sapiens/Tools/LD)
3. Analysis of transcription factor binding motifs, with the [**Regulatory Sequence Analysis Tools (RSAT)**](http://rsat.eu/)
4. ChIP-seq data for transcription factor binding, from the [**Remap**](http://pedagogix-tagc.univ-mrs.fr/remap/) database


## Flow chart of the workflow


```{r fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Annotation pipeline of genetic variants.** "), out.width = "100%", fig.width=12}
DiagrammeR::grViz("cisreg-GWAS_wf/flowchart/cisreg-GWAS.dot")
```


To select all disease trait-associated variants, we downloaded the publicly available GWAS data from the [GWAS catalog](https://www.ebi.ac.uk/gwas) website [@macarthur_new_2017].

**Note:**
  
  - The description of column headings for downloadable [GWAS catalog](https://www.ebi.ac.uk/gwas) file is  [here](https://www.ebi.ac.uk/gwas/docs/fileheaders).


## Retrieval of disease-associated variants

We define as **Disease-Associated SNPs SNPs** or **DA SNPs** the SNPs (coding and non-coding) associated to the query disease. 


It has to be noted that these SNPs are not always causal, but are likely to be included in an haplotype containng a causal SNP. 

DA SNPs are retrieved fom the [GWAS catalog](https://www.ebi.ac.uk/gwas/). 
We only keep the SNPs having an "rs" identifier.

Note that the query disease may be treated in zero, one or several GWAS, so that the same SNP may be retrieved multiple times in the initial collection obtained from Ensembl. We this remove the redundant disease-SNP associations to obtain a list of unique SNPs. 


```{r retrieve_associations}

## Retrieving the trait-variant associations from GWAS catalog
message("Retrieving information from GWAS catalog via REST interface")

## URL to the GWAS REST API query for the disease
gwascatalog.studies.urlrest <- paste(
  sep = "", 
  "https://www.ebi.ac.uk/gwas/rest/api/efoTraits/", 
  parameters$query, "/studies")
message("GWAS catalog studies link\t", gwascatalog.studies.urlrest)
gwascatalog.disease.url <- paste(
  sep = "", 
  "https://www.ebi.ac.uk/gwas/search?query=", parameters$query)
message("GWAS catalog link\t", gwascatalog.disease.url)
# gwascatalog.table.url <- paste(
#   sep = "", "https://www.ebi.ac.uk/gwas/api/search/downloads?q=text:%22", parameters$query, "%22&pvalfilter=&orfilter=&betafilter=&datefilter=&genomicfilter=&traitfilter[]=&genotypingfilter[]=&dateaddedfilter=&efo=true&facet=association")
# message("GWAS TSV table\t", gwascatalog.table.url)
GWASstudiesRestOutput <- fromJSON(
  gwascatalog.studies.urlrest, 
  content_type("application/json"), 
  simplifyDataFrame = TRUE)
names(GWASstudiesRestOutput)
# View(GWASstudiesRestOutput)
# View(GWASstudiesRestOutput[["_embedded"]])
SNPstudyLinks <- unlist(GWASstudiesRestOutput[["_embedded"]]$studies$`_links`$snps)
nbStudies <- length(SNPstudyLinks)
message("\tGWAS catalog contains ", 
        nbStudies, 
        " studies for trait ", parameters$trait)
DAsnpIDs <- vector()
i <- 0
snpTable <- data.frame()
for (studyURL in SNPstudyLinks) {
  i <- i + 1
  message("Retrieving SNPs for study ", i , "/", nbStudies, "\t", studyURL)
  studyRESToutput <- fromJSON(studyURL,  
                              simplifyDataFrame = TRUE)
  # We have to discard the _links column because it contains lists
  newSnpTable <- as.data.frame(studyRESToutput[["_embedded"]][["singleNucleotidePolymorphisms"]])[,1:6]
  
  snpTable <- rbind(snpTable, newSnpTable)
}
DAsnpIDs <- unique(snpTable$rsId)
nbDiseaseAssociatedSNPs <- length(DAsnpIDs)
message("Number of disease-associated SNPs: ", nbDiseaseAssociatedSNPs)
gwas.file <- paste(sep = "", 'data/gwas_catalog_', parameters$query,'.tsv')
# if (parameters$force.download || !file.exists(gwas.file)) {
#   message("Downloading disease-associated SNPs and Genes from GWAS catalog")
#   download.file(url = query.url,
#                 destfile = gwas.file, method = 'auto')
#   message("\tDownloaded ", parameters$query, "-associated GWAS in file ", gwas.file)
# } else {
#   message("\tDisease-associated SNPs file already there: ", gwas.file)
# }
## Check SNP IDs
DArsIDs <- grep(pattern = '^rs\\d+', DAsnpIDs, perl = TRUE, value = TRUE)
workflowSummary["DA: Disease-associated SNPs"] <- length(DArsIDs)
nonrsIDs <- setdiff(DAsnpIDs, DArsIDs)
message("SNPs with rs identifier: ", length(DArsIDs))
message("SNPs with non-rs identifier: ", length(nonrsIDs))
# for (i in 1:ncol(snpTable)) {
#   snpTable[i, ] <- as.vector(snpTable[i,])
# }

```


```{r Downloading_complementary_informations_DAsnps}

## URL to the primary GWAS page for the query disease
gwascatalog.disease.url <- paste(
  sep="", 
  "https://www.ebi.ac.uk/gwas/search?query=", parameters$query)
message("GWAS catalog link\t", gwascatalog.disease.url)

gwascatalog.table.url <- paste(sep="", "https://www.ebi.ac.uk/gwas/api/search/downloads?q=text:%22", parameters$query, "%22&pvalfilter=&orfilter=&betafilter=&datefilter=&genomicfilter=&traitfilter[]=&genotypingfilter[]=&dateaddedfilter=&efo=true&facet=association")
message("GWAS TSV table\t", gwascatalog.table.url)


message("Downloading complementary informations of disease-associated  from GWAS catalog")

query.url <- paste(sep = "", "https://www.ebi.ac.uk/gwas/api/search/downloads?q=text:%22",
                   parameters$query,
                   "%22&pvalfilter=&orfilter=&betafilter=&datefilter=&genomicfilter=&traitfilter[]=&genotypingfilter[]=&dateaddedfilter=&efo=true&facet=association")

#gwas.file <- paste(sep = "", 'gwas_catalog_', parameters$query,'.tsv')

gwas.file <- file.path(
result.dir.path["Ensembl"],
paste(sep = "", parameters$query, "_gwas_catalog", ".tsv"))

download.file(url = query.url,
              destfile = gwas.file, method = 'auto')
message("\tDownloaded ", parameters$query, "-associated GWAS in file ", gwas.file)


#message("Reading GWAS catalog in tsv format")
gwasResults <- read.delim(file = gwas.file, 
                          header = TRUE, 
                          sep = "\t", 
                          stringsAsFactors = FALSE,
                          na.strings = c(""," ","NA"))

#gwasResults$dbSNPS <- paste("rs", gwasResults$SNP_ID_CURRENT, sep = "")
#gwasResults$CHR_ID <- paste("chr", gwasResults$CHR_ID, sep = "")

#dim(gwasResults)
#View(gwasResults)
```




In total, we found `r length(DArsIDs)` **disease-associated (DA) SNPs** from GWAS catalog.


### Proportion of genomic context of the disease-associated SNPs

The barplot shows the genomic context of the `r length(DArsIDs)` SNPs associated to `r parameters$trait`.


```{r DA-SNPs, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Genomic context of disease-associated variants from GWAS catalog.** "), out.width = "80%", fig.width=8, fig.height=4.5}

# Find the genomic tag SNPs informations
message("Retrieving genomic information about ", length(DArsIDs), " disease-associated SNPs.")

tagSNPsInfo <- snpTable[, c("rsId", "functionalClass")]

# Create a data frame
Context <- tagSNPsInfo$functionalClass
DA.df <- data.frame(sort(table(Context), decreasing = FALSE))

## Make the frequencies numbers (rather than factors)
DA.df$Freq <- as.numeric(as.character(DA.df$Freq))

#Barplot of genomic context of DA-SNPs
ggplot(data=DA.df, aes(x=Context, y=Freq)) +
  geom_bar(stat = "identity", fill = "#D4AC0D", color="black")+
  geom_text(aes(label=Freq), vjust=-0.1, hjust = -0.5, size = 4)+
  xlab("Genomic context")+
  ylab("Frequency")+
  theme_test()+
  coord_flip()


## JvH:Yvon, je pense que ceci pose problème car si tu as des valeurs uniques de PUBMEDID même si un SNP est caractérisé par plusieurs études. Il n'y a pas de raison d'inclure le PUBMEDID dans ce tableau-ci, je propose donc de simplifier en exportant un tableau avec 1 colonne pour le SNP ID et 1 colonne pour le nombre d'études d'association. 
# studiesPerSNP <- 
#   gwasResults %>% 
#   dplyr::select(PUBMEDID, SNPS) %>% 
#   dplyr::group_by(SNPS, PUBMEDID) %>%
#   dplyr::summarise(N = n())

## Total number of associations (all studies)
nbAss <- nrow(gwasResults) 

## Number of studies per SNP
studiesPerSNP <- as.data.frame.table(sort(table(gwasResults$SNPS), decreasing = TRUE))
names(studiesPerSNP) <- c("SNP", "N")

## Select the SNPs with an "rs" IDs
rsID <- as.vector(
  grep(pattern = '^rs\\d+',
       studiesPerSNP$SNP, 
       perl = TRUE, value = TRUE))
nb.rsID <- length(unique(rsID))


## Summarize the results obtained so far
workflowSummary <- c(
  "GWAS studies"  = nbStudies,
  "Associations" =  nbAss,
  "Non-redundant SNPs" = nrow(studiesPerSNP),
  "SNPs demonstrated by >1 studies" = nrow(subset(studiesPerSNP, N > 1)),
  "SNPs demonstrated by 1 study" = nrow(subset(studiesPerSNP, N == 1)),
  "SNPs with rsID" = nb.rsID
)


## Print the summmary
kable(as.data.frame(workflowSummary), 
      col.names = "Number of results", 
      caption = "Disease-associated SNPs")

#View(studiesPerSNP)

```



## Linkage desequilibrium (LD)

In order to get causal SNPs, we collect from each tag SNP all the other SNPs in linkage desiquilibrium. 

We used the [Ensembl REST API](http://rest.ensembl.org/documentation/info/ld_id_get) which allows to recover SNPs in high LD (with the $r^2 = `r parameters[["r2"]]`$) by specifying the population. The *Ensembl endpoint* computes and returns LD values between the given variant set and all other variants in a window centered around the given variant set. We used the window size of set to 200 kb.


```{r linkage_desiquilibrium}

message("Getting LD SNPs from Ensembl for ", length(DArsIDs), " disease-associated SNPs. ")

## Instantiate the data frame for LD SNPs and a vector of IDs
LdSNPs <- data.frame()
LDsnpIDs <- vector()

i <- 0 ## Instantiate counter
for (rsID in DArsIDs) {
  i <- i + 1
  
  ## Generate the URL to address a query to ENSEMBL via their REST interface
  ldURL <- paste(sep = "", 
                 "http://rest.ensembl.org/ld/human/", rsID, "/",
                 parameters$ld.pop.prefix, parameters$population,
                 "?content-type=application/json",
                 "&r2=", parameters$r2, 
                 "&window_size=", as.character(parameters$ld.distance))
  newLdSNPs <- fromJSON(ldURL, simplifyDataFrame = TRUE)
  newLdSNpIDs <-  as.vector(newLdSNPs$variation2)
  if (is.null(newLdSNpIDs)) {
    newLdSNpIDs <- vector()
  } 
  
 ## Append the new LD SNps to the current collection
  # names(newLdSNPs)
  LdSNPs <- rbind(LdSNPs, 
                  data.frame(
                    variation1 = as.vector(newLdSNPs$variation1),
                    variation2 = as.vector(newLdSNPs$variation2),
                    r2 = as.vector(newLdSNPs$r2),
                    d_prime = as.vector(newLdSNPs$d_prime),
                    population = as.vector(newLdSNPs$population_name)
                  ))

#   ## This is q auick hacky solution; zill need to be updated
#   variationURL <- paste(sep = "", 
#                  "http://rest.ensembl.org/variation/human/", rsID,
#                  "?content-type=application/json")
#   newVqrSNPs <- fromJSON(variationURL, simplifyDataFrame = TRUE)
#   names(newVqrSNPs)
  
   
  # View(ldSNPs)
  nbNewSNPIDs <- length(newLdSNpIDs)
  message("\tCollected ", nbNewSNPIDs, " SNPs in LD with ", rsID)
  if (nbNewSNPIDs > parameters$max.ld.per.snp) {
    message("\t\tWarning: number of LD for tag SNP ", rsID, " (", nbNewSNPIDs,
            ") exceeds limit (", parameters$max.ld.per.snp, "). ",
            "\n\tLD SNPs are ignored for this Tag SNP. ")
  } else if (length(newLdSNpIDs) > 0) {
    LDsnpIDs <- append(LDsnpIDs, newLdSNpIDs)
  }
}

## Filter out redundancy between LD SNPs
LDsnpIDs <- unique(LDsnpIDs)
nbLDSNPs <- length(LDsnpIDs) ## Total number of LD SNPs for all the DA-SNPs
workflowSummary["LD: SNPs in Linkage Disequilibrium with DA SNPs"] <- nbLDSNPs

message("\tTotal number of LD SNPs: ", nbLDSNPs)
#sort(table(LDsnpIDs))

## Merge DA-SNPs and LD-SNPs
rsIDs <- sort(unique(c(DArsIDs, LDsnpIDs)))
nbSNPs <- length(rsIDs)
workflowSummary["DA and LD SNPs"] <- nbSNPs

message("\tTotal number of DA and LD SNPs: ", nbSNPs)

# Kable
kable(head(LdSNPs), caption = paste0("Top of the table describing the variants in Linkage disequilibrium (LD) with disease-associated SNPs within the window size of set to ", parameters$ld.distance, " kb"))

```



In this section, we gathering the informations about the DA and LD SNPs from Ensembl using the R `biomaRt` package.

```{r LD_biomart_annotation}
## biomaRt annotation
message("Gathering information from Ensembl BioMart for ", nbSNPs," SNPs (DA and LD)")
snpmart = useMart(biomart = "ENSEMBL_MART_SNP", dataset = "hsapiens_snp") # BioMart database and dataset to use.
snpInfo <- getBM(attributes = c('refsnp_source',
                                'chr_name',
                                'chrom_start',
                                'chrom_end',
                                'refsnp_id',
                                'allele_1',
                                'allele',
                                'cds_start',
                                'cds_end',
                                'ensembl_gene_stable_id',
                                'consequence_type_tv'), 
                 filters =  "snp_filter", 
                 values = rsIDs, # (DArsIDs + LDsnpIDs)
                 mart = snpmart)
# dim(snpInfo)

# Removing the duplicated information
snpInfo <- snpInfo[!duplicated(snpInfo$refsnp_id),]
# dim(snpInfo)
# View(snpInfo)
# Get gene features

# geneInfo <- getBM(attributes = c('chromosome_name', 'hgnc_symbol', 'start_position', 'end_position', 'ensembl_gene_id', 'entrezgene', 'go_id'),
#                   filters = c('chromosome_name', 'hgnc_symbol', 'start_position', 'end_position'),
#                   values = ,
#                  mart = parameters$ensemblmart
#                   )
#dim(snpInfo)

kable(head(snpInfo[, c("refsnp_source", 
                       "chr_name" , 
                       "chrom_start" , 
                       "chrom_end" ,
                       "refsnp_id", 
                       "allele", 
                       "consequence_type_tv")]), 
      caption = "LD SNPs features (top of the table)")
```


```{r DA_LD_SNPs, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Genomic context of disease-associated (DA) SNPs and LD SNPs.** "), out.width = "80%", fig.width=8, fig.height=4.5}

#Barplot of genomic context of DA and LD SNPs

snpInfo$consequence_type_tv[snpInfo$consequence_type_tv == ""] <- "intergenic"

# barplot(sort(table(snpInfo$consequence_type_tv), decreasing = TRUE),
#         #main = "Genomic context of DA and LD SNPs",
#         las=2, cex.names = 0.7, col = "#207DC2", xlab="", ylab="Number of SNPs",)

# Create a data frame
Context <- snpInfo$consequence_type_tv
DA.df <- data.frame(sort(table(Context), decreasing = FALSE))

## Make the frequencies numbers (rather than factors)
DA.df$Freq <- as.numeric(as.character(DA.df$Freq))

#Barplot of genomic context of DA-SNPs
ggplot(data = DA.df, aes(x = Context, y = Freq)) +
  geom_bar(stat = "identity", fill = "#207DC2", color = "black") +
  geom_text(aes(label = Freq), vjust = -0.1, hjust = -0.5, size = 4) +
  xlab("Genomic context") +
  ylab("Frequency") +
  theme_test() +
  coord_flip()

```




## SNPs Of Interest (SOIs)

We define as **SNPs of Interest** (**SOIs**) all the non-coding SNPs that are either associated to the disease, and in LD with these associated SNPs. We gathering the informations about LD SNPs from Ensembl using `biomaRt package`.

```{r snps_of_interest}

# Select the non-coding variant by discarding the variants with an annotated CDS start
message("Selecting SNPs of Interest (in non-coding regions) from Ensembl")

#SOIs <- subset(c, cds_start = "NA")

snpInfo$noncoding <- is.na(snpInfo$cds_start)
# table(snpInfo$noncoding)
SOIs <- subset(snpInfo, noncoding == TRUE)
# View(SOIs)
# dim(snpInfo)
# dim(SOIs)

##  assign all the SNPs without documented consequence type to the "intergenic" class
SOIs$consequence_type_tv[SOIs$consequence_type_tv == ""] <- "intergenic"

# dim(SOIs)
nbSOIs <- nrow(SOIs)
workflowSummary["SOis: SNPs of interest"] <- nbSOIs
message("\tSelected ", 
        nbSOIs, " SNPs of Interest (non-coding) among ", 
        nrow(snpInfo), " SNPs from GWAS or in LD. ")



# Make a non-coding variant bed file
SOIsBed <- data.frame(chrom = SOIs$chr_name,
                      chromStart = SOIs$chrom_start, # BEWARE: in bed the first chrom position is 0
                      chromEnd = SOIs$chrom_end + 1, # BEWARE: in bed the end position is the first position after the feature, in 0-based coordinates
                      snp = SOIs$refsnp_id)

SOIsBed$chrom <- paste("chr", SOIsBed$chrom, sep = "")


# Create a grange object for SOIsBed
SOIsBed.gr <- with(SOIsBed,
                   GRanges( seqnames = Rle(chrom),
                            ranges   = IRanges(start =  chromStart, end =  chromEnd),
                            strand   = Rle("*"), rsid = snp))


## Export rsID of SOIs in txt format
soiTxt.file <- file.path(
  result.dir.path["SOIs"], 
  paste(sep = "", parameters$query, "_SOIs", ".txt"))

write.table(x = SOIs$refsnp_id,
              file = soiTxt.file,
              quote = FALSE,
              sep = "\t",
              row.names = FALSE,
              col.names = FALSE)
#system(paste("open", result.dir.path["SOIs"]))

## Export SOIs in BED format
soiBed.file <- file.path(
  result.dir.path["SOIs"], 
  paste(sep = "", parameters$query, "_SOIs", ".bed"))

write.table(x = SOIsBed,
              file = soiBed.file,
              quote = FALSE,
              sep = "\t",
              row.names = FALSE,
              col.names = FALSE)
#system(paste("open", result.dir.path["SOIs"]))


## Export SOIs file in tsv format
soi.file <- file.path(
  result.dir.path["SOIs"], 
  paste(sep = "", parameters$query, "_SOIs", ".tsv"))

write.table(x = SOIs,
              file = soi.file,
              quote = FALSE,
              sep = "\t",
              row.names = FALSE,
              col.names = TRUE)
#system(paste("open", result.dir.path["RSAT"]))


```



```{r genomic_context_of_SOIs, out.width = "80%", fig.width=8, fig.height=4.5, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". (A) Genomic context of disease-associated (DA) SNPs and SNPs in linkage disequilibrium (LD). (B) Genomic context of the SOIs. The SOIs are selected by discarding all SNPs in conding regions (e.g. synonymous_variant, missense_variant).** ")}

#Barplot of genomic context of DA and LD SNPs
snpInfo$consequence_type_tv[snpInfo$consequence_type_tv == ""] <- "intergenic"
# barplot(sort(table(snpInfo$consequence_type_tv), decreasing = TRUE),
#         #main = "Genomic context of DA and LD SNPs",
#         las=2, cex.names = 0.7, col = "#207DC2", xlab="", ylab="Number of SNPs",)
# Create a data frame
Context <- snpInfo$consequence_type_tv
DA.df <- as.data.frame.table(sort(table(Context), decreasing = T))
## Make the frequencies numbers (rather than factors)
## JvH (2019-07-25): this is not necessary with as.data.frame.table() above
# DA.df$Freq <- unlist(DA.df$Freq)

# Barplot of genomic context of DA-SNPs
A <- ggplot(data = DA.df, aes(x = Context, y=Freq)) +
  geom_bar(stat = "identity", fill="#207DC2", color="black")+
  geom_text(aes(label=Freq), vjust=-0.1, hjust=-0.5, size=3.5)+
  xlab("Genomic context")+
  ylab("Frequency")+
  theme_classic()+
  coord_flip()


#Barplot of genomic context of the SOIs

# Create a data frame
Context <- SOIs$consequence_type_tv
DA.df <- data.frame(sort(table(Context), decreasing = T))

B <- ggplot(data=DA.df, aes(x=Context, y=Freq)) +
  geom_bar(stat="identity", fill="#207DC2", color="black")+
  geom_text(aes(label=Freq), vjust=-0.1, hjust=-0.5, size=3.5)+
  xlab("Genomic context")+
  ylab("Frequency")+
  theme_classic()+
  coord_flip()

plot_grid(A, B,  labels=c("A", "B"), ncol = 1, nrow = 2)


```




## Haplotype block


```{r haplotype}
message("Identifying haplotype blocks")


haplotype <- merge(x = SOIsBed,
                   y = LdSNPs,
                   by.x = "snp",
                   by.y = "variation2",
                   all.x = TRUE,
                   all.y = FALSE)

haplotype <- na.omit(haplotype)

# Make 
haplotype.block <- haplotype %>% 
  dplyr::select("chrom", "chromStart", "chromEnd", "variation1") %>% 
  dplyr::group_by(variation1) %>% 
  dplyr::mutate(regionStart = min(chromStart),
            regionEnd = max(chromEnd),
            Nb_SNPs = n())

# Remove lines contain NAs
haplotype.block <- na.omit(haplotype.block)

# Remove duplicated SNPs
haplotype.block <- haplotype.block[!duplicated(haplotype.block$regionStart),]


workflowSummary["Haplotype block: group of SNPs in LD"] <- nrow(haplotype.block)



#View(haplotype.block)

# Make a grange object
haplotype.block.gr <- with(haplotype.block,
GRanges( seqnames = Rle(chrom),
ranges   = IRanges(start = regionStart, end = regionEnd),
strand   = Rle("*"), rsID = variation1))

```

We identify `r nrow(haplotype.block)` haplotype blocks of a given SNP based on the pairs of LD SNPs previously retrieved from Ensembl as the limits of the region encompassing the SNPs in LD with this SNP.


```{r haplotype_block, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Number of SNPs in LD per SOI.** "), out.width = "80%", fig.width=8, fig.height=4.5}


LD <- haplotype[, c( "chrom","chromStart", "chromEnd", "snp",  "variation1")]
LD <- na.omit(LD)
LD <- LD[!duplicated(LD$snp),]
LD$chrom_start <- as.numeric(LD$chromStart)

LDgr <- with(LD,
             GRanges(seqnames = Rle(chrom),
                     ranges   = IRanges(start = chromStart, end = chromEnd),
                     strand   = Rle("*"), idLd = snp, idTag = variation1))

# Check the size of each LD block
bca.avs <- makeAVS(LDgr)
tata <- data.frame(bca.avs)
avs.size <- avsSize(bca.avs)

avs.sizes.sorted <- avs.size$Size
names(avs.sizes.sorted) <- avs.size$tagID
avs.sizes.sorted <- sort(avs.sizes.sorted, decreasing = TRUE)
if (length(avs.sizes.sorted) > 30) {
  avs.sizes.sorted <- avs.sizes.sorted[1:30]
}

par.ori <- par(no.readonly = TRUE)
par(mar = c(4,6,1,1))
barplot(avs.sizes.sorted, 
        horiz = TRUE, 
        las = 1, 
        cex.names = 1,
        col = "#0D5F05",
        #main = "Number of SNPs in LD per SOI",
        xlab = "Number of SNPs in LD",
        #ylab = "Disease-associated SNPs",
        cex.axis = 1,
        cex.lab = 1)
par(par.ori)

```



```{r heatmap_DA-LD-SNPs}
# ## SNPs in
# LD.block <- haplotype.block %>% 
#   dplyr::select(chrom, variation1, Nb_SNPs) %>% 
#   dplyr::group_by(chrom, variation1, Nb_SNPs) %>% 
#   dplyr::summarise(N = n()) 
# 
# LD.block %>%
#   ggplot(aes(chrom, variation1)) +
#   geom_tile(aes(fill = Nb_SNPs)) +
#   #scale_fill_gradient(low = "orange", high = "blue") +
#   ggtitle("") +
#    theme_bw() +
#   xlab("Chromosomes") +
#   ylab("Disease-associated SNPs") +
#   labs(fill = "LD SNPs") +
#   theme(axis.text.x = element_text( 
#     size = 19, hjust = 1))

```




## Enrichment of SOIs set for diseases

We used the `xEnricherSNPs` function (`XGR package` [@fang_xgr_2016]) to conduct in diseases ou traits enrichment analysis given a list of **SOIs**.


```{r xgr_disease_enrichment, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Enrichment of the set of SOIs for diseases, analysed with the XGR package.** "), out.width = "80%", fig.width=8, fig.height=4.5 }


message("Running enrichment analysis for diseases")
snpList <- SOIs$refsnp_id

# Run xEnricherSNPs
eTerm <- xEnricherSNPs(snpList, 
                       ontology = c("EF", 
                                    "EF_disease",
                                    "EF_phenotype", 
                                    "EF_bp"), 
                       include.LD = parameters$include.LD,
                       LD.r2 = parameters$r2,
                       size.range = c(10, 2000),
                       RData.location = "http://galahad.well.ox.ac.uk/bigdata")


# View enrichment results
enrichSNPsResults <- xEnrichViewer(eTerm, 
                                   top_num = 10, 
                                   sortBy = c("adjp", 
                                              "fdr", 
                                              "pvalue",
                                              "zscore", 
                                              "fc", 
                                              "nAnno", 
                                              "nOverlap",
                                              "or", 
                                              "none"), 
                                   decreasing = NULL,
                                   details = F)


#View(enrichSNPsResults)
# visualises enrichment results using a barplot.

bp <- xEnrichBarplot(
  eTerm, top_num = 10, 
  displayBy = c("fc", "adjp", "fdr",
                "zscore", "pvalue"), 
  FDR.cutoff = 0.05, 
  bar.label = TRUE,
  bar.label.size = 3, 
  bar.color = "yellow-orange",
  bar.width = 0.8, 
  wrap.width = NULL, 
  font.family = "sans",
  signature = TRUE)
print(bp)



```




## RSAT Var-tools

Var-tools is the subset tools of RSAT [@turatsinze_using_2008; @nguyen_rsat_2018] that perform the identification of genetic variants putatively affecting TF binding. The programm performs the scanning of alleles (variant sequences containning the SOIs) with a PSSM and compares the scores and p-values between alleles to assess the putative effect on TF binding site (TFBS), in order to predict regulatory variants.

The input data of Var-tools is a list of the SOIs. The prediction of regulatory variant by Var-tools is will done by the following steps:

1) *variation-info*: relies on the Ensembl genetic variation information (i.e. Human variants installed in the Metazoa server). This tool will retrieve the information of the variants matching the rsIDs or the information of the variants located in the genomic loci. The output  is provided in a format named varBed file, with each row giving Ensembl genetic variation information for each SOI.

2) *retrieve-variation-seq*: retrieves the sequence surrounding the variant, and produces one sequence for each allele. The tool can take as input a varBed file, and for organisms with Ensembl annotated variants. The output is provided in a format named varSeq, with each row giving one allele with its surrounding sequence. Each variant has a specific internal ID to accommodate several variants with various alleles in the same file.

3) *variation-scan*: scanning of the sequence of alleles of each SOI (in varSeq format) with a given PSSM  and compares the scores and p-values between alleles to assess the putative effect on TF binding. PSSM are used to assess the binding specificity of a TF, this affinity is calculated as a weight score (Ws) described by Hertz GZ and Stormo GD [@hertz_identifying_1999]. *variation-scan* compares the obtained Ws (Ws difference = Ws_Allele1 - Ws_Alelle2) and the P-value (P-value ratio = P-value_Allele1 / P-value_Allele2) of each of the alleles, position by position throughout the scanning window.

**Ws = ln( P(S|M))/P(S/B)**

where S is a sequence segment of the same length of M, M is the PSSM, and B is the background model. Hence, P(S|M) is the probability of the sequence given the PSSM and P(S|B) is the probability of the sequence given the background model.





```{r rsat_rest_api_R}

# # Create the vector of SOIs
# input <- paste(collapse = ",", SOIs$refsnp_id)
# 
# ## Build the API request for variation-info and submit it
# message("\tRetrieving information on variants from RSAT REST Web services")
# 
# varInfo <- POST(file.path(parameters$RsatRestUrl, "variation-info", "Homo_sapiens", "GRCh38"),
#             body = list(i_string = input,
#                         i_string_type = 'text'))
# 
# ## Parse the content returned from the server
# varInfo.content <- httr::content(varInfo, as = "text", encoding = "UTF-8")
# # class(varInfo.content)
# 
# ## Parse the JSON content
# varinfo.fromJSON <- fromJSON(varInfo.content)
# # class(varinfo.fromJSON)
# # names(varinfo.fromJSON)
# varInfo.URL <- varinfo.fromJSON$result_url
# varInfo.server.path <- varinfo.fromJSON$result_path
# 
# ## Download variation info result and store it to a local file
# varInfo.file <- file.path(
#   result.dir.path["RSAT"],
#   paste(sep = "", parameters$query, "_SOIs_info", ".varbed"))
# download.file(url = varInfo.URL, destfile = varInfo.file)
# #system(paste("open", result.dir.path["RSAT"]))
# 
# 
# 
# ## Build the API request for retrieve-variation-seq and submit it
# message("\tRetrieval of the sequences surrounding variants from RSAT REST Web services")
# varSeq <- POST(file.path(parameters$RsatRestUrl, "retrieve-variation-seq", "Homo_sapiens", "GRCh38"),
#                body = list(i_string = varInfo.server.path,
#                            i_string_type = 'piping'))
# 
# ## Parse the content returned from the server
# varSeq.content <- httr::content(varSeq, "text", encoding = "UTF-8")
# 
# ## Parse the JSON content
# varSeq.fromJSON <- fromJSON(varSeq.content)
# varSeq.server.path <- varSeq.fromJSON$result_path
# varSeq.URL <- varSeq.fromJSON$result_url
# 
# ## Download variation info result and store it to a local file
# varSeq.file <- file.path(
#   result.dir.path["RSAT"],
#   paste(sep = "", parameters$query, "_SOIs_seq", ".varSeq"))
# download.file(url = varSeq.URL, destfile = varSeq.file)
# #system(paste("open", result.dir.path["RSAT"]))

# ## Build the API request for Variation-scan and submit it
# message("Scanning variant alleles with motifs via RSAT REST services")
# varScan <- POST(file.path(parameters$RsatRestUrl, "variation-scan", "Homo_sapiens", "GRCh38"),
#                 body = list(
#                   i_string = varSeq.server.path,
#                   i_string_type = 'piping',
#                   m_string = parameters$motifDB.URL,
#                   m_string_type = "url",
#                   m_format =  "transfac"),
#                   top = 2,
#                   #uth_pval = 0.004,
#                   #lth_pval_ratio = 100,
#                   add_headers("Accept" = "application/json"))
# #                add_headers("Accept" = "text/plain"))
# 
# # var <- content(varscan, "text", encoding = "UTF-8")
# # var <- fromJSON(var)
# 
# 
# ## Parse the content returned from the server
# varScan.content <- httr::content(varScan, "text", encoding = "UTF-8")
# 
# ## Parse the JSON content
# varScan.fromJSON <- fromJSON(varScan.content)
# varScan.server.path <- varScan.fromJSON$result_path
# varScan.URL <- varScan.fromJSON$result_url
# 
# ## Download variation info result and store it to a local file
# varScan.file <- file.path(
#   result.dir.path["RSAT"],
#   paste(sep = "", parameters$query, "_SOIs_var", ".tsv"))
# download.file(url = varScan.URL, destfile = varScan.file)
# system(paste("open", result.dir.path["RSAT"]))

```



```{r importing_variascan_results}


# Importing variation-scan result
varscanFile <- file.path(
  parameters$result.dir,
  result.dirs["RSAT"],  
  paste0(parameters$query, "_varscan_web.txt"))

## Load variation-scan results
## Note: this is a temporary solution, since variation-scan should be invoked via REST Web services 
variationScan <- read.delim(file =  varscanFile,
                            header = TRUE,
                            sep = "\t",
                            comment.char = ";")

# Split var_coord column
varScanJaspar <- separate(
  data = variationScan,
  col = "var_coord",
  into = c("chrom", "pos_Start", "pos_End", "strand"),
  sep = "[\\:\\-_]", remove = F)


# Rename the motif ID
varScanJaspar$X.ac_motif <- gsub(pattern = "_", ".", varScanJaspar$X.ac_motif)


varscanColumns <- c("X.ac_motif", "var_id", "var_class", "chrom", "pos_Start", "pos_End", "strand", "best_w", "worst_w", "w_diff", "best_pval", "worst_pval", "pval_ratio", "best_variant", "worst_variant", "best_offset", "worst_offset", "min_offset_diff", "best_strand", "worst_strand", "str_change", "best_seq", "worst_seq", "minor_allele_freq")

varScanJaspar <- varScanJaspar[, varscanColumns]

#View(varScanJaspar)



nbMotifs <- length(varScanJaspar$X.ac_motif)
message("Number of ref TFBM with at least one prediction in the SNPs: ", nbMotifs)
workflowSummary["Motifs: Number of TFBM altered by the SOIs"] <- nbMotifs


varscan.unique <- varScanJaspar[!duplicated(varScanJaspar$var_id),]
nbvarScanJaspar <- length(varscan.unique$var_id)
message("Number of SNPs detected by variation-scan: ", nbvarScanJaspar)
workflowSummary["variation-scan: predicted rSNPs"] <- nbvarScanJaspar
```



### Assignation of TF from JASPAR with the corresponding motif in RSAT variation-scan

In this section, we download the Jaspar motifs identifier and  corresponding transcription factor (TF) names. We need these data for to compare and select the TF names correspending their motifs in variation-scan results.


```{r get_JASPAR_annotation}
 ## Created on January 11, 2018
## Author: <Aziz Khan>aziz.khan@ncmm.uio.no

message("Getting Jaspar annotations")

#set path to store results
results_path = path <- file.path(result.dir.path["JASPAR"])
dir.create(paste0(results_path,'pssm'), showWarnings = FALSE, recursive = TRUE)

api_root = "http://jaspar.genereg.net/api/v1/" ##Production server
#api_root = "http://127.0.0.1:8000/api/v1/" ##Local server

#get human profiles
url <- paste0(api_root,"matrix/?collection=CORE&tax_group=vertebrates&order=name&version=latest&page_size=1000&format=json")
result <- fromJSON(url)

jaspar2018_pubmedid = "29140473"

# Initialize a vector
results_matrix = c()
matrix_ids = result$results$matrix_id

# Create the vector of matrix_id from variation-scan
varscanMatrix <- varScanJaspar$X.ac_motif

inter.matrix_ids <- intersect.Vector(varscanMatrix, matrix_ids)

for (matrix_id in inter.matrix_ids)
{
  matrix_url <- paste0(api_root,"matrix/", matrix_id,".json")
  matrix_result <- fromJSON(matrix_url)
  message(paste0("Added...", matrix_id))
  
  source <- matrix_result$source;
  if(is.null(source)){
    source = 'NA';
  }
  results_matrix = rbind(results_matrix, c(matrix_id, matrix_result$name, paste(matrix_result$uniprot_ids, collapse=","), jaspar2018_pubmedid, paste(matrix_result$pubmed_ids, collapse=","), source, matrix_result$type))
  #Save raw  
   #pssm_file = paste0(results_path,'pssm/',matrix_result$matrix_id,".txt")
   pssm_file <- file.path(result.dir.path["JASPAR"],
paste(sep = "", parameters$query, "_" ,matrix_result$matrix_id,".txt"))
cat(paste0(">",matrix_id, " ", matrix_result$name,"\n"), file=pssm_file)
write.table(matrix_result$pfm[c("A", "C", "G","T")], pssm_file, sep="\t", col.names = FALSE, row.names = FALSE, append=TRUE)
}


#convert the results to dataframe and save as tsv file
jaspar_results = as.data.frame(results_matrix)
colnames(jaspar_results) = c("matrix_id", "name", "uniprot_ids", "jaspar2018_pubmedid","validation_pubmed_ids", "data_source","data_type")
write.table(jaspar_results, paste0(results_path,"jaspar2018_annotations.tsv"), sep="\t", col.names = TRUE, row.names = FALSE, quote = FALSE)


# Assignation of TF names corresponding the matrice name

varScanJasparTF <- merge(x = jaspar_results,
                         y = varScanJaspar, 
                         by.x = "matrix_id",
                         by.y = "X.ac_motif"
)


#View(varScanJasparTF)


## Export variation-scan file in tsv format
varScan.file <- file.path(
  result.dir.path["RSAT"], 
  paste(sep = "", parameters$query, "_SOIs_varTF", ".tsv"))

write.table(x = varScanJasparTF,
              file = varScan.file,
              quote = FALSE,
              sep = "\t",
              row.names = FALSE,
              col.names = TRUE)
#system(paste("open", result.dir.path["RSAT"]))
```





```{r matrices_tfs, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Distribution of TFBS potentially affected by each SOI from variation-scan results.** "), out.width = "80%", fig.width=8, fig.height=4.5}

#par(mfrow=c(2,2))  
# Barplot of motif
barplot(sort(table(varScanJasparTF$matrix_id), decreasing = TRUE),
        #main = "TFBSM affected by the SOIs ",
        xlab = "Motifs",
        ylab = "Frequency",
        las=2, cex.names = 0.5, col = "#37A3F3", border = "#05245F",
        horiz = F
        )

# Barplot of predicted rSNPs
# barplot(sort(table(varScanJasparTF$var_id), decreasing = TRUE),
#         main = "Predicted rSNPs",
#         xlab = "",
#         ylab = "Frequency",
#         las=2, cex.names = 0.5, col = "#37A3F3", border = "#05245F",
#         horiz = F
#         )
# par(mfrow=c(1,2))
```



## Chip-Seq peaks annotation using ReMap data

The ReMap catalog [@Griffon:2015en, @Cheneby:2018ix] is an integrative analysis of transcriptional regulators ChIP-seq experiments from both Public and Encode datasets [@ENCODEProjectConsortium:2012gc]. We used the `ReMapEnrich` package to identify the significant enriched region from ReMap catalog conrresponding of the TFBS altered by the potential regulatory SNPs.

The principle of the test is to measure the significance of the intersection between regions of interest and each set of ReMap peaks (a peak game for each ChIP-seq experiment in ReMap). This significance is measured with a p-value, which represents the probability of obtaining an intersection at least as important under a null hypothesis, that is, if we chose regions of the same size randomly.



```{r download_remap_data}
message("Downloading the ReMap catalog..")

## Specify the files containing bed peak catalogue in two formats`
## - bed: downloaded from ReMap
## - Rdata: exported with this script after the first loading, in order to accelerate subsequent loadins
remapBedFile <-  paste(sep = "", parameters$data.dir, "/remap2018_all_macs2_hg38_v1_2.bed.gz")

# Define the path to saving .Rda file
remapRdataFile <- file.path(parameters$data.dir,
                      paste(sep = "", "remap2018_all_macs2_hg38_v1_2", ".Rdata"))


## Load ReMap peaks from Rdata file if it is there (faster loading)
if (file.exists(remapRdataFile)) {
  message("Loading ReMap peaks from Rdata file..")
  # Load the ReMap Rdata file
  system.time({load(remapRdataFile)})
} else {

  # Downloading the ReMap peak data 
  #download.file(parameters$remapUrl, destfile = remapBedFile, method = "libcurl")
  if (file.exists(remapBedFile)) {
    message("Remap bed file already exists, skipping download. ")
    message("\t", remapBedFile)
  } else {
    message ("Downloading the ReMap catalog")
    system.time({download.file(parameters$remapUrl, 
                               dest = remapBedFile, method = "libcurl") })
  }

  ## Load the bed files
  message ("Loading ReMap peaks from bed file")
  system.time({ remap.data <- fread(file = remapBedFile) })
  
  ## Convert the bed peaks into a grange object
  message ("Converting ReMap peaks into grange objects")
  system.time({ 
    remapCatalog.gr <- with(remap.data,
                            GRanges( seqnames = Rle(V1),
                                     ranges   = IRanges(start = V2, end = V3),
                                     strand   = Rle("*"), name = V4))
  })
  
  # Save the remap data Grange format in Rda format
  message ("Saving ReMap file in Rda format")
  system.time({  save(remapCatalog.gr, file = remapRdataFile) })
}


# Compute overlaps between ReMap peaks and SNPs of interest
message("Computing intersection between ReMap peaks and SOIs")
IntersectBed <- function(a, b) {
  #library(GenomicRanges)
  my.hits <- findOverlaps(a, b, type = "any")
  my.df  <- cbind(as.data.frame(a[queryHits(my.hits)]),
                  as.data.frame(b[subjectHits(my.hits)]))
  return(my.df)
}

## Intersection between remap catalog and haplor data
#remap.SOI.overlaps <- data.frame(IntersectBed(remapCatalog, SOIsBed.gr))

#remap.SOI.overlaps <- data.frame(IntersectBed(remapCatalog.gr, haplotype.block.gr))
remap.SOI.overlaps <- data.frame(IntersectBed(remapCatalog.gr, SOIsBed.gr))
nbremap.SOI.overlaps <- nrow(remap.SOI.overlaps)
message("Number of overlaps between SOIs and ReMap peaks: ", nbremap.SOI.overlaps)
workflowSummary["ReMap: overlaps between SOIs and ReMap peaks"] <- nbremap.SOI.overlaps


## Split the ReMap peakset ID in order to obtain separate columns with the
## 1. GEO series
## 2. Transcription factor name
## 3. Tissue / condition

remap.SOI.overlaps <- separate(data = remap.SOI.overlaps, col = "name", into = c("GSE", "TF", "Tissue"), sep = "\\.", remove = FALSE)

# head(remap.SOI.overlaps)

## Export SOIs file in tsv format
remap.SOI.overlap.file <- file.path(
  result.dir.path["ReMap"], 
  paste(sep = "", parameters$query, "_SOIs_ReMap_overlaps", ".tsv"))

write.table(x = remap.SOI.overlaps,
              file = remap.SOI.overlap.file,
              quote = FALSE,
              sep = "\t",
              row.names = FALSE,
              col.names = TRUE)
#system(paste("open", result.dir.path["ReMap"]))


```



```{r remapTF, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". TFs whose TFBS \n are modified by the SOI.** "), out.width = "80%", fig.width=12, fig.height=6}

barplot(sort(table(remap.SOI.overlaps$TF), decreasing = TRUE),
        #main = "TFs whose TFBS \n are modified by the SOI",
        las=2, cex.names = 0.7, col = "#37A3F3", border = "#05245F",
        horiz = TRUE
        )


```


### Profile of ChIP-seq peaks binding to TSS regions.

We calculed the profile ChIP-seq binding to TSS regions overlapped with the haplotype blocks of the SOIs. We are defined the flanking sequences around (by default) -3kb to +3kb . Then align the peaks that are mapping to these regions, we can to generate the tagMatrix.


```{r chip-seq_peak_annotation}

# Create TxDb object contained transcript-related features of a particular hg38 human genome
txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene


## JvH (2019-07)25) : YVON, POURQUOI 3000 bp ? C'EST ENORME DU COTE DOWNSTREAM
message("Preparing the TSS regions, defined as flanking sequence of the TSS sites.")
promoter <- getPromoters(
  TxDb=txdb, 
  upstream = 3000, 
  downstream = 3000)


# BED file of SOI overlapped with the ReMap catalog
remap.SOI.bed.peak <- remap.SOI.overlaps[, c("seqnames", "start", "end")]

# Create a GRanges object of the ChIP-seq peak overlapped with the SOIs haplotype blocks.
 remap.SOI.peak.gr <- with(remap.SOI.bed.peak,
                   GRanges( seqnames = Rle(seqnames),
                            ranges   = IRanges(start =  start, end =  end),
                            strand   = Rle("*")))
 
message("Create a remap.SOI.peak matrix data..")
tagMatrix <- getTagMatrix(remap.SOI.peak.gr, windows=promoter)

```


#### Heatmap of ChIP-seq binding to TSS regions

```{r fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". # Heatmap of ChIP binding to TSS regions** "), out.width = "80%", fig.width=8, fig.height=4.5}

message("Plotting a heatmap of ChIP-seq binding to TSS regions..")
tagHeatmap(tagMatrix, xlim=c(-3000, 3000), color="blue")

# It's possible to create a heatmap of ChIP-seq binding to TSS regions using a ChIP-seq peak data in GRange format.
#peakHeatmap(remap.SOI.peak.gr, TxDb=txdb, upstream=3000, downstream=3000, color="blue")
```



#### Average Profile of ChIP-seq peaks binding to TSS region

```{r fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Average Profile of ChIP-seq peaks binding to TSS region.** "), out.width = "80%", fig.width=8, fig.height=4.5}

# Average Profile of ChIP peaks binding to TSS region

# Confidence interval estimated by bootstrap method 
#is also supported for characterizing ChIP binding profiles.


plotAvgProf(tagMatrix, xlim=c(-3000, 3000),
             conf = 0.95, resample = 1000,
            xlab="Genomic Region (5'->3')", ylab = "Read Count Frequency")

# plotAvgProf2(remap.SOI.peak.gr, TxDb=txdb, upstream=3000, downstream=3000,
#              xlab="Genomic Region (5'->3')", ylab = "Read Count Frequency")

#plotAvgProf(tagMatrix, xlim=c(-3000, 3000), conf = 0.95, resample = 1000)

```




## Regulatory SNPs analysis

The interactions between TFs and target sites are the main edges of gene regulatory networks that determines the expression levels of target genes at a particular time point during development, in a given tissue and under specific conditions.

The rSNPs alter the affinity of several TFs binding sites (TFBS). A SNP's effect on TF binding is estimated based on a position weight matrix (PWM) model for the binding specificity of the corresponding factor. 


In this section, we presente the regulatory SNPs, TFs and  TFBS potentially affected by the candidate rSNPs (SOI). To predict the rSNPs, the workflow combine the *ReMap* and *variation-scan* results tables by the `merge` R function according to the common correspondant SNPs and TFs from the merged data.


```{r rSNPs, out.width = "80%", fig.width=8, fig.height=4.5}

varscan.with.peaks <- merge(
  varScanJasparTF, 
  remap.SOI.overlaps, 
  by.x = c("var_id", "name"),
  by.y = c("rsid", "TF"))

#View(varscan.with.peaks)

kable(head(varscan.with.peaks[, c( "chrom","pos_Start", "var_id", "matrix_id", "name", "best_pval", "pval_ratio")]), caption = "Potential regulatory SNPs ")

nbrSNPs <- length(unique(varscan.with.peaks$var_id))
message("Number of rSNPs: ", nbrSNPs)
workflowSummary["rSNPs: predicted potential rSNPs"] <- nbrSNPs

nbrTFs <- length(unique(varscan.with.peaks$name))
message("Number of TFs: ", nbrTFs)
workflowSummary["TFs: TFs whose the TFBS are affected by the rSNPs"] <- nbrTFs



## Export the rSNPs file in tsv format
rsnps.file <- file.path(
  result.dir.path["rSNPs"], 
  paste(sep = "", parameters$query, "_rSNPs", ".tsv"))

write.table(x = varscan.with.peaks,
              file = rsnps.file,
              quote = FALSE,
              sep = "\t",
              row.names = FALSE,
              col.names = TRUE)
#system(paste("open", result.dir.path["rSNPs"]))

```


```{r gene_info}
# Get Ensembl gene features

#snpInfo$ensembl_gene_stable_id

ensembl = useMart(biomart = "ENSEMBL_MART_ENSEMBL", dataset = "hsapiens_gene_ensembl") # BioMart database and dataset to use.
geneInfo <- getBM(attributes = c('chromosome_name', 
                                    'start_position',
                                    'end_position',
                                    'ensembl_gene_id',
                                    'hgnc_symbol',
                                    'entrezgene_id',
                                    'go_id',
                                    'description'
                                    ), 
                     filters =  "ensembl_gene_id", 
                     values = snpInfo$ensembl_gene_stable_id, 
                     mart = ensembl)
#View(geneInfo)

# Remove duplicated gene
geneInfo.uniq <- geneInfo[!duplicated(geneInfo$start_position),]

#View(geneInfo.uniq)

# Merging snpInfo and geneInfo data tables

snpInfo.vs.geneInfo <- merge(geneInfo,
                             snpInfo,
                             by.x = "ensembl_gene_id",
                             by.y = "ensembl_gene_stable_id")
#View(snpInfo.vs.geneInfo)

# Merging gene and SNPs informations with the rSNP table

rSNPs.genes.info <- merge(varscan.with.peaks,
                          snpInfo.vs.geneInfo,
                          by.x = "var_id",
                          by.y = "refsnp_id",
                          all.x = TRUE,
                          all.y = FALSE)
#View(rSNPs.genes.info)

rSNPs.data <- rSNPs.genes.info[!duplicated(rSNPs.genes.info$var_id),]
#View(rSNPs.data)


rSNPs.data.display <- rSNPs.data[, c("seqnames", "hgnc_symbol",  "var_id", "start", "var_class", "best_variant", "worst_variant" , "best_pval", "pval_ratio", "matrix_id", "name",  "consequence_type_tv")]

kable(rSNPs.data.display, caption = "Predicted regulatory SNPs")
```


### Peak annotation 

We using `ChIPseeker` R package to annotate the ChIP-seq peaks co-localised with the rSNPs. 

```{r peak_annotation_rSNPs}

# rSNPs in BED file
rSNPs.bed <- rSNPs.data[, c("seqnames", "start", "end")]

# Create a GRanges object

 rSNPs.gr <- with(rSNPs.bed,
                   GRanges( seqnames = Rle(seqnames),
                            ranges   = IRanges(start =  start, end =  end),
                            strand   = Rle("*")))
 
 message("Performing a peak annotation..")
 
 peakAnno <- annotatePeak(rSNPs.gr, tssRegion=c(-3000, 3000),
                         TxDb=txdb, annoDb="org.Hs.eg.db")
 
 print(peakAnno)
 

```


### Genomic annotation

Location of the peaks in terms of genomic features.

```{r genomic_annotation, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Genomic annotation of the ChIP-seq paeks co-localised with the rSNPs.** "), out.width = "80%", fig.width=8, fig.height=4.5}

par(mfrow=c(2,2)) 

upsetplot(peakAnno)

#plotAnnoBar(peakAnno1)
plotAnnoPie(peakAnno, 
            legend.position = "rightside", 
            ndigit = 0.5, 
            cex = 0.1,
            col = NA,
            pie3D=FALSE)
 
#vennpie(peakAnno1, r = 0.2)

par(mfrow=c(1,2)) 
```



### Distribution of TF-binding loci relative to TSS

Percentage of binding sites upstream and downstream from the TSS of the nearest genes

```{r fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Distribution of transcription factor-binding loci\n relative to TSS.** "), out.width = "80%", fig.width=8, fig.height=4.5}

# Distribution of TF-binding loci
plotDistToTSS(peakAnno)
 
```



### Distribution of variation-scan score


```{r varscan_score_distributions, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Distributions of scores returned by variation-scan.** (**A**) Best (red) and worst (blue) p-value. (**B**) Ratio between worst (blue) and best (red) p-value ( pval_ratio = worst_pval/best_pval ). (**C**) emphazise the differences between best weigth for the putative site (red) and worst weigth for the putative site (blue). "), out.width = "80%", fig.width=8, fig.height=4.5}



par(mfrow = c(2,2))
varScanJasparTF$best_pval <- as.numeric(varScanJasparTF$best_pval)
varScanJasparTF$worst_pval <- as.numeric(varScanJasparTF$worst_pval)

best.pval <- -log10(varScanJasparTF$best_pval)
worst.pval <- -log10(varScanJasparTF$worst_pval)

pval.range <- range(c(best.pval, worst.pval))

n <- nrow(varScanJasparTF)
f <- 1:n / n
plot(sort(best.pval), f, type = "l", col = "blue", 
     xlim = pval.range,
     main = "A. P-value distributions",
     xlab = "-log10(P-value)",
     ylab = "Frequency")
lines(sort(worst.pval), f, type = "l", col = "red")
legend(1, 95, legend=c("Best P-value", "Worst P-value"),
       col=c("blue", "red"), lty=1:2, cex=0.8)


grid(col = "#DDDDDD", lty = "solid")

###################################################
## Plotting P-value ratio


pvalRatioPos <- log10(varScanJasparTF$pval_ratio)


#pvalRatio.range <- range(c(pvalRatioPos, pvalRatioNeg))

n <- nrow(varScanJasparTF)
f <- 1:n / n
plot(sort(pvalRatioPos), f, type = "l", col = "blue", 
     #xlim = pvalRatio,
     main = "B. P-value ratio distributions",
     xlab = "-log10(P-value ratio)",
     ylab = "Frequency")


grid(col = "#DDDDDD", lty = "solid")

## Weight
varScanJasparTF$best_w <- as.numeric(varScanJasparTF$best_w)
varScanJasparTF$worst_w <- as.numeric(varScanJasparTF$worst_w)

best.weight <- varScanJasparTF$best_w
worst.weight <- varScanJasparTF$worst_w

weight.range <- range(c(best.weight, worst.weight))


n <- nrow(varScanJasparTF)
f <- 1:n / n
plot(sort(best.weight), f, type = "l", col = "blue",
     xlim = weight.range,
     main = "C. Weight distributions",
     xlab = "Weight",
     ylab = "Frequency")

lines(sort(worst.weight), f, type = "l", col = "red")

legend(2000,9.5, # places a legend at the appropriate place 
      c("best.weight", "worst.weight"))

grid(col = "#DDDDDD", lty = "solid")

par(mfrow = c(1,1))

```


```{r varscan_results, out.width = "80%", fig.width=8, fig.height=4.5, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Heatmap of the scanning of the SOIs with motifs using *variation-scan*.** **A. ** P-value of the best putative site. **B. **  Ratio between worst and best P-value. ")}

## rSNPs with hight effect of motif alteration
motif.alt.effect <- varscan.with.peaks %>% 
  dplyr::select(var_id, matrix_id, best_pval) 
  #dplyr::group_by() %>% 
  #dplyr::summarise(N = n()) 

A <- ggplot(motif.alt.effect, aes(matrix_id, var_id)) + geom_tile(aes(fill = best_pval),
     colour = "white") + scale_fill_gradient(low = "white",
     high = "steelblue")+
     labs(x='', y = '')+
      theme_bw()+
      guides(fill = guide_legend(title = "P-value"))+
  ggtitle("rSNPs with hight effect of motif alteration") +
      #theme(legend.position="none")+
      theme(plot.title = element_text(hjust = 0.5,size = 10),axis.title = element_text(size=15))+
      theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),panel.grid.major= element_blank(),panel.grid.minor = element_blank())



motif.alt.pv_ratio <- varscan.with.peaks %>% 
  dplyr::select(var_id, matrix_id, pval_ratio) 
  #dplyr::group_by() %>% 
  #dplyr::summarise(N = n()) 

B <- ggplot(motif.alt.pv_ratio, aes(matrix_id, var_id)) + geom_tile(aes(fill = pval_ratio),
     colour = "white") + scale_fill_gradient(low = "white",
     high = "#145A32")+
     labs(x='', y = '')+
      theme_bw()+
      guides(fill = guide_legend(title = "Pval-ratio"))+
  #ggtitle("rSNPs with hight effect of motif alteration") +
      #theme(legend.position="none")+
      theme(plot.title = element_text(hjust = 0.5,size = 10),axis.title = element_text(size=15))+
      theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),panel.grid.major= element_blank(),panel.grid.minor = element_blank())

plot_grid(A, B,  labels=c("A", "B"), ncol = 1, nrow = 2)
```


### Visualization of TFBS in logos

```{r download_logo_from_jaspar}

## Adapted from: <Aziz Khan>aziz.khan@ncmm.uio.no

#set path to store results
results_path = path <- file.path(result.dir.path["JASPAR"])
dir.create(paste0(results_path,'logo'), showWarnings = FALSE, recursive = TRUE)

api_root = "http://jaspar.genereg.net/api/v1/" ##Production server
#api_root = "http://127.0.0.1:8000/api/v1/" ##Local server

#get human profiles
url <- paste0(api_root,"matrix/?collection=CORE&tax_group=vertebrates&order=name&version=latest&page_size=1000&format=json")
result <- fromJSON(url)

#jaspar2018_pubmedid = "29140473"

# Initialize a vector
results_matrix = c()
matrix_ids = result$results$matrix_id

# Create the vector of matrix_id from variation-scan
rSNPsMatrix <- varscan.with.peaks$matrix_id

inter.matrix_ids <- intersect.Vector(rSNPsMatrix, matrix_ids)

for (matrix_id in inter.matrix_ids)
{
  matrix_url <- paste0(api_root,"matrix/", matrix_id,".json")
  matrix_result <- fromJSON(matrix_url)
  message(paste0("Downloading...", matrix_result$sequence_logo))
  
  source <- matrix_result$source;
  if(is.null(source)){
    source = 'NA';
  }

# Downloag and save logo
logo_url <- matrix_result$sequence_logo
logo_file = paste0(results_path, 'logo/', matrix_result$matrix_id, ".svg")

download.file(logo_url, destfile = logo_file, method = "libcurl")
}

```


We used the `grImport2` package for R imports the TFBSM SVG images directly into R.

```{r grImport2_import_svg, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Logos for TFBSM affected by the rSNPs.** "), out.width = "80%", fig.width=8, fig.height=4.5}

simple <- readPicture("~/cisreg-GWAS_results/EFO_0001068/JASPARlogo/MA0507.1.svg")
grid.picture(simple)


img.list <- list.files(path="~/cisreg-GWAS_results/EFO_0001068/JASPARlogo/", pattern=".svg", all.files = T, full.names = F, no.. = T) 

```


### rSNPs and the corresponding TFs 

```{r out.width = "80%", fig.width=8, fig.height=4.5, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),".Predicted rSNPs and the corresponding TFs whose DNA binding sites are affected.**")}

## rSNPs and associated TFs

snp.tf <- varscan.with.peaks %>% 
  dplyr::select(name, var_id) %>% 
  dplyr::group_by(var_id, name) %>% 
  dplyr::summarise(N = n()) 

ggplot(snp.tf, aes(name, var_id)) + geom_tile(aes(fill = var_id)) +
     labs(x='TFs', y = 'rSNPs') +
      theme_bw()+
      guides(fill = FALSE) +
  #ggtitle("") +
      #theme(legend.position="none")+
      theme(plot.title = element_text(hjust = 0.5,size = 10),axis.title = element_text(size=15))+
      theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),panel.grid.major= element_blank(),panel.grid.minor = element_blank())


```




### Predicting tissue/cell type specific transcription factor binding sites

```{r TFs_vs_rSNPs, out.width = "80%", fig.width=8, fig.height=4.5, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),".TFs whose DNA binding sites are affected by the rSNPs.** **A. ** Predicted TFs across representative tissue/cell types as reported by ReMap catalog.  **B. ** Number of TFs by GEO series")}

#remap.SOI.overlaps.unique <- remap.SOI.overlaps[!duplicated(remap.SOI.overlaps),]

## TF and tissue
tissue <- varscan.with.peaks %>% 
  dplyr::select(name, Tissue) %>% 
  dplyr::group_by(Tissue, name) %>% 
  dplyr::summarise(N = n()) 

A <- ggplot(data=tissue, aes(x=Tissue, y=N, fill=name)) +
geom_bar(stat="identity", position=position_dodge(), color="black") +
  theme_bw() +
  labs(x='Tissue', y = 'Frequency')+
      guides(fill = guide_legend(title = "TFs"))+
  ggtitle("Predicted TFs in the corresponding tissue/cell type") +
  coord_flip() +
      #theme(legend.position="none")+
      theme(plot.title = element_text(hjust = 0.5,size = 10),
            axis.title = element_text(size=10))+
      theme(axis.text.x = element_text(angle = 0, 
                                       vjust = 1, 
                                       hjust = 1, 
                                       size = 5),
            axis.text.y = element_text(size=5),
            panel.grid.major= element_blank(),
            panel.grid.minor = element_blank())


## GEO accession
GSE.df <- varscan.with.peaks %>% 
  dplyr::select(GSE, name) %>% 
  dplyr::group_by(GSE, name) %>% 
  dplyr::summarise(N = n()) 

B <-  ggplot(data=GSE.df, aes(x=GSE, y=name, fill=N)) +
geom_bar(stat="identity", position=position_dodge()) +
  #theme_cowplot() +
   theme_bw() +
  labs(x='GSE', y = 'TFs') +
      guides(fill = FALSE)+
  #ggtitle("TFs by GEO series") +
      #theme(legend.position="none")+
      theme(plot.title = element_text(hjust = 0.5,size = 10),
            axis.title = element_text(size=10))+
      theme(axis.text.x = element_text(angle = 90, 
                                       vjust = 1, 
                                       hjust = 1, 
                                       size = 5),
            axis.text.y = element_text(size=5),
            panel.grid.major= element_blank(),
            panel.grid.minor = element_blank())

#grid.arrange(A, B, C, D,  ncol=2, nrow = 2)
plot_grid(A, B,  labels=c("A", "B"), ncol = 2, nrow = 1)

```




## rSNPs and associated genes

```{r rSNPs_genes_features, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". rSNPs and associated genes.** "), out.width = "80%", fig.width=8, fig.height=4.5}

# rSNPs and associated genes
gene.ass <- rSNPs.data %>% 
  dplyr::select(hgnc_symbol, var_id) %>% 
  dplyr::group_by(hgnc_symbol, var_id) %>% 
  dplyr::summarise(N = n()) 

ggplot(gene.ass, aes(hgnc_symbol, var_id)) + geom_tile(aes(fill = var_id)) +
     labs(x='Genes', y = 'rSNPs') +
      theme_bw()+
      guides(fill = FALSE) +
  #ggtitle("rSNPs and associated genes") +
      #theme(legend.position="none")+
      theme(plot.title = element_text(hjust = 0.5,size = 10),axis.title = element_text(size=15))+
      theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),panel.grid.major= element_blank(),panel.grid.minor = element_blank())


```


### Functional enrichment analysis 

We performe the functional enrichment analysis to identify predominant biological themes among the genes associated with the rSNPs by incorporating biological knowledge provided by biological ontologies.


```{r functional_analysis_rSNPs, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Functional enrichment analysis of the gene in reactome biological pathway.** "), out.width = "80%", fig.width=8, fig.height=4.5}

rSNPs.gene.bed <- rSNPs.data[, c("seqnames", "start.1", "end.1")]

rSNPs.gene.gr <- with(rSNPs.gene.bed,
                   GRanges( seqnames = Rle(seqnames),
                            ranges   = IRanges(start =  start.1, end =  end.1),
                            strand   = Rle("*")))

 geneAnno <- annotatePeak(rSNPs.gene.gr, tssRegion=c(-3000, 3000),
                         TxDb=txdb, annoDb="org.Hs.eg.db")
 
print(geneAnno)
 
gene <- seq2gene(rSNPs.gene.gr, tssRegion = c(-1000, 1000), flankDistance = 3000, TxDb=txdb)
pathway2 <- enrichPathway(gene)
head(pathway2, 2)

dotplot(pathway2)

```



In this section, we running `gprofiler` R function to identify enriched processes among significant genes associated with the rSNPs

```{r gprofiler}

## Selecte the Ensembl gene ID
ENS <- unique(na.omit(rSNPs.data$ensembl_gene_id))

## Running gProfiler
gprofiler_results <- gprofiler(query = ENS, 
                                  organism = "hsapiens",
                                  ordered_query = F, 
                                  exclude_iea = F, 
                                  max_p_value = 0.05, 
                                  max_set_size = 0,
                                  correction_method = "fdr",
                                  hier_filtering = "none", 
                                  domain_size = "annotated")


## Subset and reorder gProfiler results to only include columns of interest
gprofiler_results_reordered <- gprofiler_results[, c("term.id", "domain", "term.name", "p.value", "overlap.size", "term.size", "intersection")]

## Order the results by p-adjusted value
gprofiler_results_reordered <- gprofiler_results_reordered[order(gprofiler_results_reordered$p.value), ]

## Extract only the 'GO' terms from the results
# gprofiler_results_GOs <- gprofiler_results_reordered[grep('GO:', gprofiler_results_reordered$term.id), ]

```


```{r out.width = "80%", fig.width=8, fig.height=4.5, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1)," .")}


gprofiler.df <- gprofiler_results_reordered %>% 
  dplyr::select(domain, intersection, p.value) %>% 
  dplyr::group_by(domain, intersection, p.value) %>% 
  dplyr::summarise(N = n()) 

ggplot(gprofiler.df, aes(intersection, domain)) + 
  geom_tile(aes(fill = p.value),
     colour = "white") + scale_fill_gradient(low = "gray", 
  high = "steelblue") +
     labs(x='Ensembl gene ID', y = 'Domaines') +
      theme_bw()+
  guides(fill = guide_legend(title = "P-value"))+
  #ggtitle("rSNPs and associated genes") +
      #theme(legend.position="none")+
      theme(plot.title = element_text(hjust = 0.5,size = 10),axis.title = element_text(size=15))+
      theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),panel.grid.major= element_blank(),panel.grid.minor = element_blank())


```



```{r out.width = "80%", fig.width=8, fig.height=4.5, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Functional enrichment of genes using DOSE (annotates genes with human disease association).")}

# Functional enrichment of genes using DOSE
entrez.gene.id <- na.omit(rSNPs.data$entrezgene_id)
x <- enrichDO(entrez.gene.id)

dotplot(x)
```



### Exploring tissue-specific gene enrichment results

The below bar charts shown the tissue-specific gene enrichment.

```{r tissue_specific_gene_enrichment, out.width = "80%", fig.width=8, fig.height=4.5, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Tissue-specific gene enrichment.** **A. ** the x-axis shows each of the tissues, and the y-axis represents the tissue-specific gene enrichment (−Log10(P−Value)) values. **B. **  the x-axis shows each of the tissues, and the y-axis represents the fold-change values of the tissue-specific gene enrichment. ")}


# Select the associated genes with the rSNPs
inputGenes<- unique(na.omit(rSNPs.data$hgnc_symbol))
gs<-GeneSet(geneIds=inputGenes,organism="Homo Sapiens",geneIdType=SymbolIdentifier())
output<-teEnrichment(inputGenes = gs)

seEnrichmentOutput<-output[[1]]
enrichmentOutput<-setNames(data.frame(assay(seEnrichmentOutput),row.names = rowData(seEnrichmentOutput)[,1]), colData(seEnrichmentOutput)[,1])
enrichmentOutput$Tissue<-row.names(enrichmentOutput)


s <- ggplot(enrichmentOutput,aes(x=reorder(Tissue,-Log10PValue),y=Log10PValue,label = Tissue.Specific.Genes,fill = Tissue))+
      geom_bar(stat = 'identity')+
      labs(x='', y = '-LOG10(P-Adjusted)')+
      theme_bw()+
      theme(legend.position="none")+
      theme(plot.title = element_text(hjust = 0.5,size = 20),axis.title = element_text(size=15))+
      theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),panel.grid.major= element_blank(),panel.grid.minor = element_blank())


h <- ggplot(enrichmentOutput,aes(x=reorder(Tissue,-fold.change),y=fold.change,label = Tissue.Specific.Genes,fill = Tissue))+
      geom_bar(stat = 'identity')+
      labs(x='', y = 'Fold change')+
      theme_bw()+
      theme(legend.position="none")+
      theme(plot.title = element_text(hjust = 0.5,size = 20),axis.title = element_text(size=15))+
      theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),panel.grid.major= element_blank(),panel.grid.minor = element_blank())


# grid.arrange(s, h, labels=c("A", "B"), ncol=1, nrow = 2,   top = textGrob("Tissue-specific gene enrichment ", gp=gpar(fontsize=12,font=3)))

plot_grid(s, h, labels=c("A", "B"), ncol = 1, nrow = 2)
```


## Workflow summary

```{r workflow_summary}

kable(as.data.frame(workflowSummary), caption = "Statiscal results of workflow summary.")

```



## Libraries and versions0

```{r session_info}
session_info()

```



```{r end_time}
# End time
# end.time <- Sys.time()
# time100.2 <- round(end.time - start.time,2)
# print(round(end.time - start.time,2))

proc.time() - ptm
```






## References
