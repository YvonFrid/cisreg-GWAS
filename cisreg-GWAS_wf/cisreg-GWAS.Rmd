---
title: "Detection of  regulatory SNPs in GWAS studies"
author: 'Yvon Mbouamboua, Pascal Rihet, Thi-Thuy-Nga Nguyen, Andrew Parton, Aziz Khan
  & Jacques van Helden '
date: "`r Sys.Date()`"
always_allow_html: yes
output:
  html_document:
    code_folding: hide
    fig_caption: yes
    highlight: zenburn
    self_contained: no
    theme: cerulean
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    fig_caption: yes
    highlight: zenburn
    toc: yes
    toc_depth: 3
  ioslides_presentation:
    colortheme: dolphin
    fig_caption: yes
    fig_height: 6
    fig_width: 7
    fonttheme: structurebold
    highlight: tango
    incremental: no
    keep_md: no
    smaller: yes
    theme: cerulean
    toc: yes
    widescreen: yes
  word_document:
    toc: yes
    toc_depth: 3
  slidy_presentation:
    fig_caption: yes
    fig_height: 6
    fig_width: 7
    highlight: tango
    incremental: no
    keep_md: no
    self_contained: no
    smaller: yes
    theme: cerulean
    toc: yes
    toc_float: yes
    widescreen: yes
  beamer_presentation:
    colortheme: dolphin
    fig_caption: yes
    fig_height: 6
    fig_width: 7
    fonttheme: structurebold
    highlight: tango
    incremental: no
    keep_tex: no
    slide_level: 2
    theme: Montpellier
    toc: yes
bibliography: bibliography.bib
editor_options:
  chunk_output_type: console
font-family: Garamond
font-import: http://fonts.googleapis.com/css ?family=Risque
csl: biomed-central.csl
subtitle: Disease
address: TAGC lab, Aix-Marseille Université, France
transition: linear
---


```{r start_time}
## Start time 
#start.time <- Sys.time()

ptm <- proc.time()
```


```{r setup, include=FALSE, size="huge"}
message("Loading knitr library")
if (!require("knitr", quietly = TRUE)) {
  message("Installing knitr library")
  install.packages("knitr", dependencies = TRUE)
}
require(knitr)

## Default parameters for displaying the slides
knitr::opts_chunk$set(
  echo = TRUE, 
  eval = TRUE, 
  fig.width = 7, 
  fig.height = 5, 
  fig.align = "center", 
#  fig.path = paste(sep = "", "figures/", parameters$query, "_"),
  size = "tiny", 
  warning = FALSE, 
  results = TRUE, 
  message = FALSE, 
  comment = "")

## Load custom functions
R.files <- list.files(path = "R/",pattern = "*.R", full.names = TRUE)
for (file in R.files) {
  source(file)
}

```

  
```{r parameters, echo=FALSE}

## Define user-specified parameters for the analyses
## Parameters
parameters <- list(
  working.dir = getwd(),
  output.dir = "~/cisreg-GWAS_results",
  #query =  "EFO_0001068", # malaria
  #query = "EFO_0001360", # type ii diabetes mellitus
  #query = "HP_0100806", # sepsis
  #query = "EFO_0000249", # Alzheimer's disease
  query =  "EFO_0008407", # tuberculosis
  # query =  "EFO_0008407", # tuberculosis
  ld.pop.prefix = "1000GENOMES:phase_3:",
  population = "AFR",
  r2 = 0.8,
  ld.distance = 200,
  max.ld.per.snp = 500, # ignore LDs for a given tag SNP if there are more too many of them
  include.LD = "AFR", # additional SNPs in LD with Lead SNPs in XGR package
  update.flowcharts = TRUE, # Update the flowcharts with graphviz dot
  flowchart.formats = c("pdf", "png"), # List of formats to generate
  flowchart.format = "pdf", # Format for insertion in the report,
  force.download = FALSE, # if TRUE, files are downloaded even if already present
  #ensemblmart = useMart(biomart = "ENSEMBL_MART_ENSEMBL", dataset = "hsapiens_gene_ensembl"),
  GWAS.REST = FALSE, # If TRUE, use the REST interface of the GWAS catalog to retrieve the associations (much slower than the download, so we do not recmmend it)
  RSAT.rest = FALSE, ## If TRUE, use RSAT REST interface to predict rSNPs
  RSAT.rest.root = "http://rsat-tagc.univ-mrs.fr/rsat/rest/",
  RSAT.varscan.pval = 1e-4,
  RSAT.varscan.pval.ratio = 100,
  jaspar.rest.root = "http://jaspar.genereg.net/api/v1/",
  motifDB.URL = "http://jaspar.genereg.net/download/CORE/JASPAR2018_CORE_vertebrates_non-redundant_pfms_transfac.txt",
  remapUrl =  "http://pedagogix-tagc.univ-mrs.fr/remap/download/remap2018/hg38/MACS/remap2018_all_macs2_hg38_v1_2.bed.gz"
)


fig.nb <- 0 ## Initialize figure counter

message("\tWorking directory: ", parameters$working.dir)


## Define a data dir for the data downloaded from other sources
parameters$data.dir = file.path(parameters$output.dir, "data")
message("Data directory\t", parameters$data.dir)
dir.create(parameters$data.dir, showWarnings = FALSE, recursive = TRUE)

## Define result directory for the current EFO 
## by concatenating the output dir and the query ID
parameters$result.dir = file.path(parameters$output.dir, parameters$query)
message("Result directory\t", parameters$result.dir)
dir.create(parameters$result.dir, showWarnings = FALSE, recursive = TRUE)

parameters$figure.dir = file.path(parameters$result.dir, "figures")
message("Result directory\t", parameters$figure.dir)
dir.create(parameters$figure.dir, showWarnings = FALSE, recursive = TRUE)

knitr::opts_chunk$set(fig.path = paste(
  sep = "", parameters$figure.dir, parameters$query, "_"))


## Initialise a vector to summarize the results
workflowSummary <- vector()



```



```{r libraries, include=FALSE,  eval=TRUE, echo=FALSE, warning=FALSE}
message("Loading required libraries")
cran.libraries.to.install <- 
  c("dplyr",   
    "devtools",
    "ggplot2", 
    "gridExtra",
    "cowplot",
    "scales",
    "tidyr",
    #"VSE",
    "DiagrammeR",
    "VennDiagram",
    "jsonlite",
    "httr",
    "xml2",
    "RCurl",
    "data.table",
    #"gProfileR",
    "DOSE"
 
  )     

bioconductor.libraries.to.install <- c(
  "biomaRt",
  "GenomicRanges",
  "ChIPpeakAnno",
  "ChIPseeker",
  "TxDb.Hsapiens.UCSC.hg38.knownGene",
  "ReactomePA",
  "enrichplot",
  #"rGREAT",
  "XGR",
  #"FunciSNP",
  "TissueEnrich",
  "grImport2"

)

message("Loading CRAN libraries")
for (lib in cran.libraries.to.install) {
  if (require(lib, character.only = TRUE, quietly = TRUE)) {
    message("\tLoaded library\t", lib)
  } else {
    message("Installing CRAN library\t", lib)
    install.packages(lib, dependencies = TRUE)
  }
  require(lib, character.only = TRUE, quietly = TRUE)
}

message("Loading Bioconductor libraries")
for (lib in bioconductor.libraries.to.install) {
  if (!require(lib, character.only = TRUE, quietly = TRUE)) {
    #   message("\tLoaded library\t", lib)
    # } else {
    message("Installing Bioconductor library\t", lib)
    if (!("BiocManager" %in% rownames(installed.packages()))) {
      install.packages("BiocManager")
    } 
    
        BiocManager::install(lib, dependencies = TRUE, ask = FALSE)
    if (!require(lib, character.only = TRUE, quietly = TRUE)) {
      stop("Could not install and load package ", lib)
    }
  }
#   require(lib, character.only = TRUE, quietly = TRUE)
}

## For github libraries we need to know the account for each package -> we encode this as a named vector
github.libraries.to.install <- c("ReMapEnrich" = "remap-cisreg")
message("Loading github libraries")
for (lib in names(github.libraries.to.install)) {
  if (require(lib, character.only = TRUE, quietly = TRUE)) {
    message("\tLoaded library\t", lib)
  } else {
    library(devtools)
    message("Installing github library\t", lib)
    github.path <- paste(sep = "/", github.libraries.to.install[lib], lib)
    install_github(github.path, dependencies = TRUE)
    #    install_github(github.path, dependencies = TRUE, force = TRUE)
  }
  require(lib, character.only = TRUE, quietly = TRUE)
}

```



```{r output_directories}

message("Creating output sub-directories for disease\t", parameters$query)

# Result directory (export result tables)
result.subdir <- c(TagSNPs = "TagSNPs",
                 Ensembl = "Ensembl",
                 SOIs = "SOIs",
                 ReMap = "ReMap",
                 RSAT = "RSAT",
#                 JASPAR = "JASPAR",
                 rSNPs = "rSNPs")
result.dir.path <- file.path(parameters$result.dir, result.subdir)
names(result.dir.path) <- names(result.subdir) ## entry names were lost with the file.paths

result.dir.path["JASPAR"] <- file.path(parameters$data.dir, "JASPAR")

for (dir in c(parameters$result.dir, result.dir.path)) {
  message("\t", dir)
  dir.create(dir, showWarnings = FALSE, recursive = TRUE)
}

## Prepare a table for the output files
outfiles <- vector()

```

## Parameters

```{r disease_of_interest}
## Identify the disease based on the EFO ID
message("Identifying the disease of interest")
diseaseURL <- paste(sep = "/", 
                    "http://www.ebi.ac.uk/gwas/rest/api/efoTraits", 
                    parameters$query)

GWASstudiesRestOutput <- fromJSON(
  diseaseURL, 
  content_type("application/json"), 
  simplifyDataFrame = FALSE)


parameters$trait <- GWASstudiesRestOutput$trait

## Generate a table displaying the parameters for the report
kable(t(as.data.frame(parameters))[,1], 
      col.names = c("Parameter value"))

```



## Introduction

This report summarises the results of **cisreg-GWAS**, an automatic workflow to predict the impact of genetic variations on cis-regulation, based on the integration of complementary data types. 

1. **Genome-Wise Association Studies** (**GWAS**), obtained from [**GWAS catalog**](https://www.ebi.ac.uk/gwas/).

2. **Linkage desequilibrium** (**LD**) data, from [**Ensembl**](https://www.ensembl.org/Homo_sapiens/Tools/LD).

3. Analysis of **transcription factor binding motifs**, with the variation tools ot the [**Regulatory Sequence Analysis Tools (RSAT)**](http://rsat.eu/), and motif collections from **(JASPAR)**[JvH_signature_300dpi_blue.jpg].

4. ChIP-seq data for transcription factor binding, from the [**Remap**](http://pedagogix-tagc.univ-mrs.fr/remap/) database.


## Flow chart of the workflow


```{r fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Annotation pipeline of genetic variants.** "), out.width = "100%", fig.width=12}
DiagrammeR::grViz("flowchart/cisreg-GWAS.dot")
```

## Retrieval of disease-associated variants

To select all disease trait-associated variants, we downloaded the publicly available GWAS data from the [GWAS catalog](https://www.ebi.ac.uk/gwas) website [@macarthur_new_2017].

We define as **Disease-Associated SNPs SNPs** or **DA SNPs** the SNPs (coding or not) associated to the query disease. 

**Notes**

1. DA SNPs are not always causal, but are likely to be included in an haplotype containng a causal SNP. 

2. DA SNPs are retrieved fom the [GWAS catalog](https://www.ebi.ac.uk/gwas/). The description of column headings for downloadable [GWAS catalog](https://www.ebi.ac.uk/gwas) file is  [here](https://www.ebi.ac.uk/gwas/docs/fileheaders).

3. We only keep the SNPs having an "rs" identifier, for the sake of inter-operability with other databases further used in this workflow.

4. A given query disease may be treated in zero, one or several GWAS, so that the same SNP may be retrieved multiple times in the initial collection obtained from Ensembl. We thus remove the redundant disease-SNP associations to obtain a list of unique SNPs. 



```{r retrieve_associations_gwas_catalog_REST}

## Retrieving the trait-variant associations from GWAS catalog via the REST interface.
## NOTE: this method is much slower than the direct download (chink below) 
## and returns incomplete results (less associations than via the download) so by default we do not use it. 

if (parameters$GWAS.REST) {
  ## Retrieving the trait-variant associations from GWAS catalog
  message("Retrieving information from GWAS catalog via REST interface")
  
  ## URL to the GWAS REST API query for the disease
  gwascatalog.studies.urlrest <- paste(
    sep = "", 
    "https://www.ebi.ac.uk/gwas/rest/api/efoTraits/", 
    parameters$query, "/studies")
  message("GWAS catalog studies link\t", gwascatalog.studies.urlrest)
  gwascatalog.disease.url <- paste(
    sep = "", 
    "https://www.ebi.ac.uk/gwas/search?query=", parameters$query)
  message("GWAS catalog link\t", gwascatalog.disease.url)
  # gwascatalog.table.url <- paste(
  #   sep = "", "https://www.ebi.ac.uk/gwas/api/search/downloads?q=text:%22", parameters$query, "%22&pvalfilter=&orfilter=&betafilter=&datefilter=&genomicfilter=&traitfilter[]=&genotypingfilter[]=&dateaddedfilter=&efo=true&facet=association")
  # message("GWAS TSV table\t", gwascatalog.table.url)
  GWASstudiesRestOutput <- fromJSON(
    gwascatalog.studies.urlrest, 
    content_type("application/json"), 
    simplifyDataFrame = TRUE)
  names(GWASstudiesRestOutput)
  # View(GWASstudiesRestOutput)
  # View(GWASstudiesRestOutput[["_embedded"]])
  
  ## Count the number of studies
  nbStudies <- nrow(GWASstudiesRestOutput[["_embedded"]]$studies)
  message("\tGWAS catalog contains ", 
          nbStudies, 
          " studies for trait ", parameters$trait)
  
  ## Get the URLs of the studies
  SNPstudyLinks <- unlist(GWASstudiesRestOutput[["_embedded"]]$studies$`_links`$snps)
  
  ## Collect the disease-associated SNPs (DA SNPs) in the GWAS catalog
  DAsnpIDs <- vector()
  i <- 0
  gwas.results <- data.frame()
  for (studyURL in SNPstudyLinks) {
    i <- i + 1
    message("Retrieving SNPs for study ", i , "/", nbStudies, "\t", studyURL)
    studyRESToutput <- fromJSON(studyURL,  
                                simplifyDataFrame = TRUE)
    
    # We have to discard the _links column because it contains lists
    current.study <- studyRESToutput[["_embedded"]][["singleNucleotidePolymorphisms"]]
    
    if (is.null(current.study$rsId)) {
      message("\tnot a single SNP in this study")
    } else {
      #  newgwas.results <- as.data.frame(current.study)[,1:6]
      newgwas.results <- data.frame(
        studyURL = studyURL,
        rsID = current.study$rsId,
        merged = current.study$merged,
        functionalClass = current.study$functionalClass
      )
      message("\tadding ", nrow(newgwas.results), " SNPs")
      gwas.results <- rbind(gwas.results, newgwas.results)
    }
    
  }
  
  ## Export the GWAS-SNP associations
  outfiles["GWAS-SNP associations (REST)"] <- file.path(
    result.dir.path["Ensembl"],
    paste(sep = "", parameters$query, "_gwas-catalog_REST", ".tsv"))
  
  write.table(x = gwas.results, file = outfiles["GWAS-SNP associations (REST)"] , 
              quote = FALSE, row.names = FALSE, col.names = TRUE, sep = "\t")
  
  #### Compute statistics about the associations ####
  
  ## Count the number of associations
  nbAssoc <- nrow(gwas.results)
  
  # View(gwas.results)
  
  ## Collect unique SNP IDs
  DAsnpIDs <- unique(as.vector(gwas.results$rsID))
  nb.DA.SNPs <- length(DAsnpIDs)
  message("Unique disease-associated SNPs: ", nb.DA.SNPs)
  
  ## Check SNP IDs
  DA.rsIDs <- grep(pattern = '^rs\\d+', DAsnpIDs, perl = TRUE, value = TRUE)
  nb.DA.rsIDs <- nb.DA.rsIDs
  #workflowSummary["DA: Disease-associated SNPs"] <- nb.DA.rsIDs
  nonrsIDs <- setdiff(DAsnpIDs, DA.rsIDs)
  
  workflowSummary <- append(workflowSummary, c(
    "Association Studies for the disease" = nbStudies,
    "Disease SNP associations" = nbAssoc,
    "Disease-Associated SNPs (unique IDs)" = nb.DA.SNPs,
    "SNPs with rs identifier" = nb.DA.rsIDs,
    "SNPs with non-rs identifier" = length(nonrsIDs)))
  
  message("Studies: ", nbStudies)
  message("Associations: ", nbAssoc)
  message("Unique SNP IDs: ", nb.DA.SNPs)
  message("SNPs with rs identifier: ", nb.DA.rsIDs)
  message("SNPs with non-rs identifier: ", length(nonrsIDs))
}

```


```{r retrieve_associations_gwas_catalog_download}

## Here we download information from the Web site of the GWAS catalog 
message("Downloading informations of disease-associated SNPs from GWAS catalog")


## URL to the primary GWAS page for the query disease
gwascatalog.disease.url <- paste0(
  "https://www.ebi.ac.uk/gwas/search?query=", parameters$query)
message("GWAS catalog link\t", gwascatalog.disease.url)

gwascatalog.table.url <- paste0(
  "https://www.ebi.ac.uk/gwas/api/search/downloads?q=text:%22",
  parameters$query, 
  "%22&pvalfilter=&orfilter=&betafilter=&datefilter=&genomicfilter=&traitfilter[]=&genotypingfilter[]=&dateaddedfilter=&efo=true&facet=association")
message("URL to downmoad info from GWAS catalog\t", gwascatalog.table.url)


query.url <- paste(sep = "", "https://www.ebi.ac.uk/gwas/api/search/downloads?q=text:%22",
                   parameters$query,
                   "%22&pvalfilter=&orfilter=&betafilter=&datefilter=&genomicfilter=&traitfilter[]=&genotypingfilter[]=&dateaddedfilter=&efo=true&facet=association")

#gwas.file <- paste(sep = "", 'gwas_catalog_', parameters$query,'.tsv')

outfiles["GWAS-SNP associations (GWAS downlaod)"] <- file.path(
  result.dir.path["Ensembl"],
  paste(sep = "", parameters$query, "_gwas-catalog_download", ".tsv"))



download.file(url = query.url,
              destfile = outfiles["GWAS-SNP associations (GWAS downlaod)"], 
              method = 'auto')
message("\tDownloaded ", 
        parameters$query, "-associated GWAS in file\t", 
        outfiles["GWAS-SNP associations (GWAS downlaod)"])


#message("Reading GWAS catalog in tsv format")
gwas.results <- read.delim(file = outfiles["GWAS-SNP associations (GWAS downlaod)"], 
                          header = TRUE, 
                          sep = "\t", 
                          stringsAsFactors = FALSE,
                          na.strings = c(""," ","NA"))
# View(gwas.results)

#### Compute statistics about the associations ####

## Number of studies
nbStudies <- length(unique(gwas.results$STUDY.ACCESSION))

## Count the number of associations
nbAssoc <- nrow(gwas.results)
message("Downloaded ", nbAssoc, " associations from GWAS catalog (may contain redundant SNPs)")

## Collect unique SNP IDs
DAsnpIDs <- unique(as.vector(gwas.results$SNPS))
nb.DA.SNPs <- length(DAsnpIDs)
message("Unique disease-associated SNPs: ", nb.DA.SNPs)

## Check SNP IDs
DA.rsIDs <- grep(pattern = '^rs\\d+', DAsnpIDs, perl = TRUE, value = TRUE)
nb.DA.rsIDs <- length(DA.rsIDs)
#workflowSummary["DA: Disease-associated SNPs"] <- nb.DA.rsIDs
nonrsIDs <- setdiff(DAsnpIDs, DA.rsIDs)

workflowSummary <- append(workflowSummary, c(
  "Association Studies for the disease" = nbStudies,
  "Disease SNP associations" = nbAssoc,
  "Disease-Associated SNPs (unique IDs)" = nb.DA.SNPs,
  "SNPs with rs identifier" = nb.DA.rsIDs,
  "SNPs with non-rs identifier" = length(nonrsIDs)))

message("Studies: ", nbStudies)
message("Associations: ", nbAssoc)
message("Unique SNP IDs: ", nb.DA.SNPs)
message("SNPs with rs identifier: ", nb.DA.rsIDs)
message("SNPs with non-rs identifier: ", length(nonrsIDs))

#gwas.results$dbSNPS <- paste("rs", gwas.results$SNP_ID_CURRENT, sep = "")
#gwas.results$CHR_ID <- paste("chr", gwas.results$CHR_ID, sep = "")

#dim(gwas.results)
#View(gwas.results)
```




In total, we found `r nb.DA.rsIDs` **disease-associated (DA) SNPs** from GWAS catalog.


## Getting information about DA SNPs from BioMart

The barplots shows the number of DA-SNPs per chromosome and the  genomic context of the `r length(nb.DA.rsIDs)` SNPs associated to `r parameters$trait`.

The barplot shows the genomic context of the `r nb.DA.rsIDs` SNPs associated to `r parameters$trait`.



```{r DA_SNPs, out.width = "80%", fig.width=8, fig.height=4.5}

# Find the genomic tag SNPs informations
message("Analysing genomic context for ", nb.DA.rsIDs, " disease-associated SNPs.")

if (parameters$GWAS.REST) {
  tagSNPsInfo <- gwas.results[, c("rsId", "functionalClass")]
  Context <- tagSNPsInfo$functionalClass
} else {
  tagSNPsInfo <- gwas.results[, c("SNPS", "CONTEXT")]
  Context <- tagSNPsInfo$CONTEXT
}

# names(gwas.results)

# # Create a data frame
# DA.df <- data.frame(sort(table(Context), decreasing = FALSE))
# 
# ## Make the frequencies numbers (rather than factors)
# DA.df$Freq <- as.numeric(as.character(DA.df$Freq))
# 
# #Barplot of genomic context of DA-SNPs
# ggplot(data=DA.df, aes(x=Context, y=Freq)) +
#   geom_bar(stat = "identity", fill = "#207DC2", color="black")+
#   geom_text(aes(label=Freq), vjust=-0.1, hjust = -0.5, size = 4)+
#   xlab("Genomic context")+
#   ylab("Frequency")+
#   theme_cowplot()+
#   coord_flip()

## Number of studies per SNP
studiesPerSNP <- as.data.frame.table(sort(table(gwas.results$SNPS), decreasing = TRUE))
names(studiesPerSNP) <- c("SNP", "N")

## Select the SNPs with an "rs" IDs
rsID <- as.vector(
  grep(pattern = '^rs\\d+',
       studiesPerSNP$SNP, 
       perl = TRUE, value = TRUE))
nb.rsID <- length(unique(rsID))


## Summarize the results obtained so far
workflowSummary <- append(workflowSummary, c(
#  "GWAS studies"  = nbStudies,
#  "Associations" =  nbAssoc,
#  "Non-redundant SNPs" = nrow(studiesPerSNP),
  "SNPs demonstrated by >1 studies" = nrow(subset(studiesPerSNP, N > 1)),
  "SNPs demonstrated by 1 study" = nrow(subset(studiesPerSNP, N == 1)),
  "SNPs with rsID" = nb.rsID)
)

## Print the summmary
kable(as.data.frame(workflowSummary), 
      col.names = "Number of results", 
      row.names = TRUE,
      caption = "Disease-associated SNPs")

#View(studiesPerSNP)

```





```{r biomart_filter_da_ids}

#### Select DA SNP IDs valid for Biomart  #### 

## Get coordinates of DA SNPs from BioMart
message("Gathering information from Ensembl BioMart for ", nb.DA.rsIDs," DA SNPs")

## Define the BioMart database and dataset to use.
DA.snpmart <- useMart(biomart = "ENSEMBL_MART_SNP", dataset = "hsapiens_snp") 

## Get information from BioMart
DA.snpInfo <- getBM(
  attributes = c(
    'refsnp_id',
    'refsnp_source',
    'chr_name',
    'chrom_start',
    'chrom_end'), 
  filters =  "snp_filter", 
  uniqueRows = TRUE,
  values = DA.rsIDs, # (DA.rsIDs + LDsnpIDs)
  mart = DA.snpmart)

# Removing the duplicated information
DA.snpInfo <- DA.snpInfo[!duplicated(DA.snpInfo$refsnp_id),]
# View(DA.snpInfo)

## Select valid SNP IDs, i.e. those for which we could get information from BioMart
valid.DA.snp.ID <- DA.snpInfo$refsnp_id
nb.valid.DA.snp.ID <- length(valid.DA.snp.ID)

message("Identified ", nb.valid.DA.snp.ID, 
        " rsIDs with information in Biomart among ", nb.DA.SNPs, " DA SNPs")
workflowSummary["valid rsIDs for BioMart"] <- nb.valid.DA.snp.ID

```



```{r da_snps_barplot, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". **A. ** Disease-associated SNPs per chromosome. **B. ** Genomic context of disease-associated SNPs from GWAS catalog.** "), out.width="50%", fig.width=6, fig.height=8}


par(mfrow = c(1,2)) 
#par.ori <- par(no.readonly = TRUE)
par(mar = c(5.1, 8, 9.1, 1.1))
## Draw a barplot with the number of disease-associated SNPs per chromosome
barplot(height = sort(table(DA.snpInfo$chr_name), decreasing = FALSE), 
        #main = "Disease-associated SNPs per chromosome",
        main = "A",
        xlab = "SNPs",
        ylab = "Chromosomes",
        cex.axis = 0.8,
        horiz = TRUE,
        col = "#BBDDFF",
        cex.names = 0.7, 
        las = 1)

df <- sort(table(tagSNPsInfo$CONTEXT),  decreasing = FALSE)
max.context <- length(df)
x <- barplot(height = df,
        #main = "Disease-associated SNPs per chromosome",
        xlim = c(0, max(df)*1.1),
        cex.axis = 1,
        main = "B",
         xlab = "SNPs",
        cex.lab = 1,
        horiz = TRUE, 
        col = "#DBDDFF",
        cex.names = 0.7, 
        las = 1)
text(x = df[1:max.context], y = x, labels = df[1:max.context], cex = 0.7, pos = 4)
#par(par.ori)

par(mfrow = c(1,1)) 
```


## Linkage desequilibrium (LD)

In order to get causal SNPs, we collect from each tag SNP all the other SNPs in linkage desiquilibrium. 

We used the [Ensembl REST API](http://rest.ensembl.org/documentation/info/ld_id_get) which allows to recover SNPs in high LD (with the $r^2 = `r parameters[["r2"]]`$) by specifying the population. The *Ensembl endpoint* computes and returns LD values between the given variant set and all other variants in a window centered around the given variant set. We used the window size of set to 200 kb.


```{r linkage_desiquilibrium}

message("Getting LD SNPs from Ensembl for ", length(valid.DA.snp.ID), " disease-associated SNPs. ")

## Instantiate the data frame for LD SNPs and a vector of IDs
LdSNPs <- data.frame()
LDsnpIDs <- vector()
# LdSNPstats <- data.frame()
ldGroups <- list()
  
i <- 0 ## Instantiate counter
for (rsID in valid.DA.snp.ID) {
  i <- i + 1
  
  ## Generate the URL to address a query to ENSEMBL via their REST interface
  ldURL <- paste(sep = "", 
                 "http://rest.ensembl.org/ld/human/", rsID, "/",
                 parameters$ld.pop.prefix, parameters$population,
                 "?content-type=application/json",
                 "&r2=", parameters$r2, 
                 "&window_size=", as.character(parameters$ld.distance))

  newLdSNPs <- fromJSON(ldURL, simplifyDataFrame = TRUE, flatten = TRUE)
  
  
  newLdSNpIDs <-  as.vector(newLdSNPs$variation2)
  if (is.null(newLdSNpIDs)) {
    newLdSNpIDs <- vector()
  } 
  
  ## Append the new LD SNps to the current collection
  # names(newLdSNPs)
  currentLdSNPs <- data.frame(
    variation1 = as.vector(newLdSNPs$variation1),
    variation2 = as.vector(newLdSNPs$variation2),
    r2 = as.vector(newLdSNPs$r2),
    d_prime = as.vector(newLdSNPs$d_prime),
    population = as.vector(newLdSNPs$population_name))
  
  LdSNPs <- rbind(LdSNPs, currentLdSNPs)
  
  ## Add the DA SNP to the LD SNPs with correlation of 1
  # LdSNPs <- rbind(LdSNPs, 
  #                 data.frame(
  #                   variation1 = rsID,
  #                   variation2 = rsID,
  #                   r2 = 1,
  #                   d_prime = 1,
  #                   population = parameters$population
  #                 ))
  
  ldGroups[[rsID]] <- c(rsID, as.vector(currentLdSNPs$variation2))
  
#   ## This is a auick hacky solution; zill need to be updated
#   variationURL <- paste(sep = "", 
#                  "http://rest.ensembl.org/variation/human/", rsID,
#                  "?content-type=application/json")
#   newVqrSNPs <- fromJSON(variationURL, simplifyDataFrame = TRUE)
#   names(newVqrSNPs)
  
   
  # View(ldSNPs)
  nbNewSNPIDs <- length(newLdSNpIDs)
  if (nbNewSNPIDs > parameters$max.ld.per.snp) {
    message("\t\tWarning: number of LD for tag SNP ", rsID, " (", nbNewSNPIDs,
            ") exceeds limit (", parameters$max.ld.per.snp, "). ",
            "\n\tLD SNPs are ignored for this Tag SNP. ")
  } else if (length(newLdSNpIDs) > 0) {
    LDsnpIDs <- append(LDsnpIDs, newLdSNpIDs)
  }
  message("\tDA SNP", 
          "\t", i, "/", nb.valid.DA.snp.ID, 
           "\t", rsID, 
          "\t", nbNewSNPIDs, " LD SNPs",
          "\tCurrent total: ", length(LDsnpIDs))

  # ## Add info on the number of LD SNPs to the table describing DA SNPs
  # LdSNPstats <- rbind(LdSNPstats,
  #                     data.frame(
  #                       rsID = rsID,
  #                       LD.SNPs = nbNewSNPIDs,
  #                       cumLD.SNPs = length(LDsnpIDs)
  #                     ))

}


## Identify the LD groups from the pairs of LDs
# length(unique(LdSNPs$variation1))


## Filter out redundancy between LD SNPs
LDsnpIDs <- unique(LDsnpIDs)
nbLDSNPs <- length(LDsnpIDs) ## Total number of LD SNPs for all the DA-SNPs
workflowSummary["LD: SNPs in Linkage Disequilibrium with DA SNPs"] <- nbLDSNPs
message("\tTotal number of LD SNPs: ", nbLDSNPs)
#sort(table(LDsnpIDs))

## Merge DA-SNPs and LD-SNPs
DA.LD.IDs <- sort(unique(c(valid.DA.snp.ID, LDsnpIDs)))

## Make sure all IDs (including those of LD SNPs we just retrieved) start with "rs"
rsIDs <- grep(pattern = "^rs", x = DA.LD.IDs, value = TRUE)
nbSNPs <- length(rsIDs)
workflowSummary["Union of DA and LD SNPs"] <- nbSNPs
message("\tTotal number of DA and LD SNPs: ", nbSNPs)

# Kable
kable(head(LdSNPs), caption = paste0(
  "Top of the table describing the variants in linkage disequilibrium (LD) with disease-associated (DA) SNPs. ",
  " Min r2 = ", parameters$r2, ".", 
  "Max window size = ", parameters$ld.distance, " kb. "))

```



```{r ld_snp_plot, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". SNPs in linkage disequilibrium (LD).** "), out.width = "80%", fig.width=8, fig.height=4.5}

# Draw a barplot of SNPs in LD
nb.ld.snps <- table(factor(LdSNPs$variation1))

barplot(as.vector(nb.ld.snps),
        horiz = F,
        cex.axis = 1,
        cex.lab = 1,
        las = 1, 
        main = "SNPs in linkage disequilibrium",
        xlab = "DA-SNPs",
        ylab = "LD SNPs",
        cex.names = 0.8,
        col = "#006699")

```


In this section, we gathering the informations about the DA and LD SNPs from Ensembl using the R `biomaRt` package.

```{r biomart_SNP_annotation}
## Get SNP annotations from  biomaRt
message("Gathering information from Ensembl BioMart for ", nbSNPs," SNPs (DA and LD)")

## Define thje BioMart database and dataset to use.
snpmart <- useMart(biomart = "ENSEMBL_MART_SNP", dataset = "hsapiens_snp") 

## Get information from BioMart
snpInfo <- getBM(attributes = c('refsnp_source',
                                'chr_name',
                                'chrom_start',
                                'chrom_end',
                                'refsnp_id',
                                'allele_1',
                                'allele',
                                'minor_allele_freq',
                                'cds_start',
                                'cds_end',
                                'ensembl_gene_stable_id',
                                'consequence_type_tv'), 
                 filters =  "snp_filter", 
                 values = rsIDs, # (valid.DA.snp.ID + LDsnpIDs)
                 mart = snpmart)
# dim(snpInfo)

# Removing the duplicated information
snpInfo <- snpInfo[!duplicated(snpInfo$refsnp_id),]
# dim(snpInfo)
# View(snpInfo)
# Get gene features

# geneInfo <- getBM(attributes = c('chromosome_name', 'hgnc_symbol', 'start_position', 'end_position', 'ensembl_gene_id', 'entrezgene', 'go_id'),
#                   filters = c('chromosome_name', 'hgnc_symbol', 'start_position', 'end_position'),
#                   values = ,
#                  mart = parameters$ensemblmart
#                   )
#dim(snpInfo)

# kable(head(snpInfo[, c("refsnp_source", 
#                        "chr_name" , 
#                        "chrom_start" , 
#                        "chrom_end" ,
#                        "refsnp_id", 
#                        "allele", 
#                        "consequence_type_tv")]), 
#       caption = "LD SNPs features (top of the table)")

```


```{r DA_LD_SNPs, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Genomic context of disease-associated (DA) SNPs and LD SNPs.** "), out.width = "80%", fig.width=8, fig.height=4.5}

# Barplot of genomic context of DA and LD SNPs
snpInfo$consequence_type_tv[snpInfo$consequence_type_tv == ""] <- "unknown"

# barplot(sort(table(snpInfo$consequence_type_tv), decreasing = TRUE),
#         #main = "Genomic context of DA and LD SNPs",
#         las=2, cex.names = 0.7, col = "#207DC2", xlab="", ylab="Number of SNPs",)

# Create a data frame
Context <- snpInfo$consequence_type_tv
DA.df <- data.frame(sort(table(Context), decreasing = FALSE))

## Make the frequencies numbers (rather than factors)
DA.df$Freq <- as.numeric(as.character(DA.df$Freq))

#Barplot of genomic context of DA-SNPs
ggplot(data = DA.df, aes(x = Context, y = Freq)) +
  geom_bar(stat = "identity", fill = "#999966", color = "black") +
  geom_text(aes(label = Freq), vjust = -0.1, hjust = -0.5, size = 4) +
  xlab("Genomic context") +
  ylab("Frequency") +
  theme_test() +
  coord_flip()


```


## SNPs Of Interest (SOIs)

We define as **SNPs of Interest** (**SOIs**) all the non-coding SNPs that are either associated to the disease, and in LD with these associated SNPs. We gathering the informations about LD SNPs from Ensembl using `biomaRt package`.

```{r snps_of_interest}

# Select the non-coding variant by discarding the variants with an annotated CDS start
message("Selecting SNPs of Interest (in non-coding regions) from Ensembl")

#SOIs <- subset(c, cds_start = "NA")

snpInfo$noncoding <- is.na(snpInfo$cds_start)
# table(snpInfo$noncoding)
SOIs <- subset(snpInfo, noncoding == TRUE)
# View(SOIs)
# dim(snpInfo)
# dim(SOIs)

##  assign all the SNPs without documented consequence type to the "unknown" class
SOIs$consequence_type_tv[SOIs$consequence_type_tv == ""] <- "unknown"

# dim(SOIs)
nbSOIs <- nrow(SOIs)
workflowSummary["SOIs: SNPs of interest (non-coding DA or LD)"] <- nbSOIs
message("\tSelected ", 
        nbSOIs, " SNPs of Interest (non-coding) among ", 
        nrow(snpInfo), " SNPs (DA or LD). ")



# Make a non-coding variant bed file
SOIsBed <- data.frame(chrom = SOIs$chr_name,
                      chromStart = SOIs$chrom_start, # BEWARE: in bed the first chrom position is 0
                      chromEnd = SOIs$chrom_end + 1, # BEWARE: in bed the end position is the first position after the feature, in 0-based coordinates
                      snp = SOIs$refsnp_id)

SOIsBed$chrom <- paste("chr", SOIsBed$chrom, sep = "")


# Create a grange object for SOIsBed
SOIsBed.gr <- with(SOIsBed,
                   GRanges( seqnames = Rle(chrom),
                            ranges   = IRanges(start =  chromStart, end =  chromEnd),
                            strand   = Rle("*"), rsid = snp))


## Export rsID of SOIs in txt format
outfiles["SOI IDs (txt)"] <- file.path(
  result.dir.path["SOIs"], 
  paste(sep = "", parameters$query, "_SOI_IDs", ".txt"))

write.table(x = SOIs$refsnp_id,
              file = outfiles["SOI IDs (txt)"],
              quote = FALSE,
              sep = "\t",
              row.names = FALSE,
              col.names = FALSE)
#system(paste("open", result.dir.path["SOIs"]))

## Export SOIs in BED format
outfiles["SOI coordinates (bed)"] <- file.path(
  result.dir.path["SOIs"], 
  paste(sep = "", parameters$query, "_SOIs", ".bed"))

write.table(x = SOIsBed,
              file = outfiles["SOI coordinates (bed)"],
              quote = FALSE,
              sep = "\t",
              row.names = FALSE,
              col.names = FALSE)
# system(paste("open", result.dir.path["SOIs"]))


## Export SOIs file in tsv format
outfiles["SOI descriptions (tsv)"] <- file.path(
  result.dir.path["SOIs"], 
  paste(sep = "", parameters$query, "_SOIs", ".tsv"))

write.table(x = SOIs,
              file = outfiles["SOI descriptions (tsv)"],
              quote = FALSE,
              sep = "\t",
              row.names = FALSE,
              col.names = TRUE)
#system(paste("open", result.dir.path["RSAT"]))


```



```{r genomic_context_of_SOIs, out.width = "100%", fig.width=8, fig.height=6, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Genomic feature of the SNPs of Interest (SOIs)** **A. ** Number of the SOIs per chromosome. **B. ** Genomic context of the SOIs, which  were selected by discarding all SNPs in conding regions (e.g. synonymous_variant, missense_variant).")}
par(mfrow = c(2,2)) 
par.ori <- par(no.readonly = TRUE)
par(mar = c(5.1, 8, 3.1, 2.1))

## Draw a barplot with the number of LD SNPs per chromosome
barplot(height = sort(table(snpInfo$chr_name), decreasing = FALSE), 
        #main = "Disease-associated SNPs per chromosome",
        main = "A",
        xlab = "SNPs",
        ylab = "Chromosomes",
        cex.axis = 1,
        horiz = TRUE,
        col = "#006699",
        cex.names = 1, 
        las = 1)

ld.df <- sort(table(snpInfo$consequence_type_tv),  decreasing = FALSE)
max.context <- length(ld.df)
x <- barplot(height = ld.df,
        #main = "Disease-associated SNPs per chromosome",
        xlim = c(0, max(ld.df)*1.1),
        cex.axis = 1,
        main = "B",
        xlab = "SNPs",
        cex.lab = 1,
        horiz = T, 
        col = "#006699",
        cex.names = 1, 
        las = 1)
text(x = ld.df[1:max.context], y = x, labels = ld.df[1:max.context], cex = 0.7, pos = 4)

## Draw a barplot with the number of disease-associated SNPs per chromosome
barplot(height = sort(table(SOIs$chr_name), decreasing = FALSE), 
        #main = "Disease-associated SNPs per chromosome",
        main = "C",
        xlab = "SNPs",
        ylab = "Chromosomes",
        cex.axis = 1,
        horiz = TRUE,
        col = "#ffcc99",
        cex.names = 1, 
        las = 1)
#box()


soi.df <- sort(table(SOIs$consequence_type_tv),  decreasing = FALSE)
max.context <- length(soi.df)
x <- barplot(height = soi.df,
        #main = "Disease-associated SNPs per chromosome",
        xlim = c(0, max(soi.df)*1.1),
        cex.axis = 1,
        main = "D",
        xlab = "SNPs",
        cex.lab = 1,
        horiz = T, 
        col = "#ffcc99",
        cex.names = 1, 
        las = 1)
text(x = soi.df[1:max.context], y = x, labels = soi.df[1:max.context], cex = 0.7, pos = 4)
#box()
```




## LD groups

We compute the coordinates of each LD group.s


```{r haplotype_block, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Number of SNPs in LD per SOI.** "), out.width = "100%", fig.width=9, fig.height=4.5}

message("Identifying haplotype blocks")

# View(LdSNPs)

LD.SNP.coord <- as.data.frame(merge(x = SOIsBed,
                                    y = LdSNPs,
                                    by.x = "snp",
                                    by.y = "variation2",
                                    all.x = TRUE,
                                    all.y = FALSE))
# View(LD.SNP.coord)
# names(LD.SNP.coord)

## Tricky way to ensure that each SNP is included in its own LD block
LD.SNP.coord$variation1 <- as.vector(LD.SNP.coord$variation1)
LD.SNP.coord$r2 <- as.vector(LD.SNP.coord$r2)
LD.SNP.coord$d_prime <- as.vector(LD.SNP.coord$d_prime)
LD.SNP.coord$population <- as.vector(LD.SNP.coord$population)

self.LD <- is.na(LD.SNP.coord$variation1)
LD.SNP.coord[self.LD, "variation1"] <- as.vector(LD.SNP.coord[self.LD, "snp"])
LD.SNP.coord[self.LD, "r2"] <- 1
LD.SNP.coord[self.LD, "d_prime"] <- 1
LD.SNP.coord[self.LD, "population"] <- parameters$population
# LD.SNP.coord[self.LD, ]


# sort(table(LD.SNP.coord$snp))
# length(unique(LD.SNP.coord$snp))
# length(unique(LD.SNP.coord$variation1))
# dim(SOIsBed)
# names(SOIsBed)
# dim(LdSNPs)
# length(sort(table(LdSNPs$variation1)))
# length(sort(table(LdSNPs$variation2)))
# names(LdSNPs)
# length(unique(LdSNPs$variation))

# Remove lines contain NAs
# LD.SNP.coord <- na.omit(LD.SNP.coord)
# 
# # Number of LD SNPs per DA-SNP
# haplotype.block <- LD.SNP.coord %>%
#   dplyr::select("chrom", "chromStart", "chromEnd", "variation1") %>%
#   dplyr::group_by(variation1) %>%
#   dplyr::mutate(
#     regionStart = min(chromStart),
#     regionEnd = max(chromEnd),
#     Nb_SNPs = n())
# 
# View(haplotype.block)
# 
# workflowSummary["Haplotype block: group of SNPs in LD"] <- nrow(haplotype.block)
# # dim(haplotype.block)
# 
# # Make a grange object
# haplotype.block.gr <- with(haplotype.block,
# GRanges( seqnames = Rle(chrom),
# ranges   = IRanges(start = regionStart, end = regionEnd),
# strand   = Rle("*"), rsID = variation1))

# ## Vector of the DA SNPs
# var <- haplotype$variation1
# 
# ## Count the number of LD SNPs per DA SNP
# ld.block <- sort(table(var), decreasing = TRUE)

## Display the top 30 haplotype blocks
## Barplot of haplotype blocks
par.ori <- par(no.readonly = TRUE)
par(mar = c(5.1, 7, 3.1, 1.1))

# max.snps <- min(length(ld.block), 20)
# barplot(ld.block[1:max.snps], 
#         horiz = TRUE, 
#         las = 1, 
#         cex.names = 1,
#         col = "#0D5F05",
#         #main = "Number of SNPs in LD per SOI",
#         xlab = "Number of SNPs in LD",
#         #ylab = "Disease-associated SNPs",
#         cex.axis = 1,
#         cex.lab = 1)
# 

## Collect the coordinates of the LD groups
# length(ldGroups)
i <- 1
nb.ldGroups <- length(ldGroups)
ldGroup.info <- data.frame()
for (i in 1:length(ldGroups)) {
  snp <- names(ldGroups)[i]
  message("Computing LD block coordinates for DA SNP\t", i, "/", nb.ldGroups, "\t", snp)
  ldGroup <- as.vector(unlist(ldGroups[i]))
  current.ldGroup.info <- data.frame(
    DA.SNP = snp,
    nb.SNPs = length(ldGroup),
    chr_name = snpInfo[snpInfo$refsnp_id == snp, "chr_name"],
    chrom_start = min(snpInfo[snpInfo$refsnp_id %in% ldGroup, "chrom_start"]),
    chrom_end = max(snpInfo[snpInfo$refsnp_id %in% ldGroup, "chrom_end"])
  )
  ldGroup.info <- rbind(ldGroup.info, current.ldGroup.info)
  # names(snpInfo)
}
ldGroup.info$size <- ldGroup.info$chrom_end - ldGroup.info$chrom_start + 1
row.names(ldGroup.info) <- ldGroup.info$DA.SNP
# View(ldGroup.info)
# sum(ldGroup.info$size == 1)

# Change the format of chromosome
ldGroup.info$chr_name <- paste("chr", ldGroup.info$chr_name, sep = "")

# Create a granges object for ldGroup.info
haplotype.blocks.gr <- with(ldGroup.info,
                   GRanges( seqnames = Rle(chr_name),
                            ranges   = IRanges(start =  chrom_start, end =  chrom_end),
                            snp = DA.SNP,
                            strand   = Rle("*")))


par(mfrow = c(1,2))

## Draw a plot with LD block sizes: kilobases versus nb of SNPs
plot(ldGroup.info$nb.SNPs, ldGroup.info$size/1000, 
     main = "LD block sizes",
     las = 1, col = "blue",
     xlab = "SNPs per LD block", ylab = "LD block size (kb)",
     panel.first = grid())


## Draw a barplot with the number of SNPs per LD block (one block per DA SNP)
ldGroup.snpNb <- ldGroup.info$nb.SNPs
names(ldGroup.snpNb) <- ldGroup.info$DA.SNP
snps.per.ldblock <- sort(ldGroup.snpNb, decreasing = TRUE)
max.snps <- min(length(snps.per.ldblock), 20)
y <- barplot(
  snps.per.ldblock[1:max.snps],
  main = "Top-ranking LD blocks",
  horiz = TRUE, 
  xlim = c(0, max(snps.per.ldblock)*1.1),
  las = 1, 
  cex.names = 0.8,
  col = "#0D5F05",
  #main = "Number of SNPs in LD per SOI",
  xlab = "SNPs per LD block",
  #ylab = "Disease-associated SNPs",
  cex.axis = 1,
  cex.lab = 1)
text(x = snps.per.ldblock[1:max.snps], y = y, labels = snps.per.ldblock[1:max.snps], pos = 4)

par(par.ori)
```

We identify `r nrow(ldGroup.info)`  groups of SNPs in linkage disequilibrium (LD group), i.e. one for each one of the disease-associated SNP (DA-SNP) based on the pairs of LD SNPs retrieved from Ensembl. We then compute the coordinates of the LD blocks as the limits of the region encompassing all the SNPs in LD with a given DA SNP.


```{r heatmap_DA-LD-SNPs}
# ## SNPs in
# LD.block <- haplotype.block %>%
#   dplyr::select(chrom, variation1, Nb_SNPs) %>%
#   dplyr::group_by(chrom, variation1, Nb_SNPs) %>%
#   dplyr::summarise(N = n())
# 
# LD.block %>%
#   ggplot(aes(chrom, variation1)) +
#   geom_tile(aes(fill = Nb_SNPs)) +
#   #scale_fill_gradient(low = "orange", high = "blue") +
#   ggtitle("") +
#    theme_bw() +
#   xlab("Chromosomes") +
#   ylab("Disease-associated SNPs") +
#   labs(fill = "LD SNPs") +
#   theme(axis.text.x = element_text(
#     size = 10, hjust = 1, angle = 90))

```




## Enrichment of SOIs set for Experimental Factor Ontology (EFO)

We used the `xEnricherSNPs()` function (`XGR package`, [@fang_xgr_2016]) to analyse the enrichment of SNPs for all the traits mapped to EFO in the GWAS catalogues.


```{r SNPs_EFO_enrichment, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Enrichment of the set of SOIs for the Experiment Factor Ontology (EFO), analysed with the XGR package.** "), out.width = "80%", fig.width=8, fig.height=4.5, eval=FALSE}


message("Running enrichment analysis (xEnricherSNPs) for diseasess")
snpList <- SOIs$refsnp_id

# Run xEnricherSNPs
eTerm <- c(snpList, 
           ontology = c("EF", 
                        "EF_disease",
                        "EF_phenotype", 
                        "EF_bp"), 
           include.LD = parameters$include.LD,
           LD.r2 = parameters$r2,
           size.range = c(10, 2000),
           RData.location = "http://galahad.well.ox.ac.uk/bigdata")


# View enrichment results
enrichSNPsResults <- xEnrichViewer(
  eTerm, 
  sortBy = c("adjp", 
             "fdr", 
             "pvalue",
             "zscore", 
             "fc", 
             "nAnno", 
             "nOverlap",
             "or", 
             "none"), 
  decreasing = NULL,
  details = F)


#View(enrichSNPsResults)
# visualises enrichment results using a barplot.

par(mfrow = c(1,2))

bp.fc <- xEnrichBarplot(
  eTerm, top_num = 20, 
  displayBy = "fc", 
  FDR.cutoff = 0.05, 
  bar.label = TRUE,
  bar.label.size = 3, 
  bar.color = "yellow-orange",
  bar.width = 0.8, 
  wrap.width = NULL, 
  font.family = "sans",
  signature = TRUE)
print(bp.fc)

bp.adjp <- xEnrichBarplot(
  eTerm, top_num = 20, 
  displayBy = "adjp", 
  FDR.cutoff = 0.05, 
  bar.label = TRUE,
  bar.label.size = 3, 
  bar.color = "yellow-orange",
  bar.width = 0.8, 
  wrap.width = NULL, 
  font.family = "sans",
  signature = TRUE)
print(bp.adjp)

par(mfrow = c(1,1))



```




## RSAT variation-tools

variation-tools is the subset tools of RSAT [@turatsinze_using_2008; @nguyen_rsat_2018] that perform the identification of genetic variants putatively affecting TF binding. The programm performs the scanning of alleles (variant sequences containning the SOIs) with a PSSM and compares the scores and p-values between alleles to assess the putative effect on TF binding site (TFBS), in order to predict regulatory variants.

The input data of variation-tools is a list of the SOIs. The prediction of regulatory variant by variation-tools is will done by the following steps:

1) *variation-info*: relies on the Ensembl genetic variation information (i.e. Human variants installed in the Metazoa server). This tool will retrieve the information of the variants matching the rsIDs or the information of the variants located in the genomic loci. The output  is provided in a format named varBed file, with each row giving Ensembl genetic variation information for each SOI.

2) *retrieve-variation-seq*: retrieves the sequence surrounding the variant, and produces one sequence for each allele. The tool can take as input a varBed file, and for organisms with Ensembl annotated variants. The output is provided in a format named varSeq, with each row giving one allele with its surrounding sequence. Each variant has a specific internal ID to accommodate several variants with various alleles in the same file.

3) *variation-scan*: scanning of the sequence of alleles of each SOI (in varSeq format) with a given PSSM  and compares the scores and p-values between alleles to assess the putative effect on TF binding. PSSM are used to assess the binding specificity of a TF, this affinity is calculated as a weight score (Ws) described by Hertz GZ and Stormo GD [@hertz_identifying_1999]. *variation-scan* compares the obtained Ws (Ws difference = Ws_Allele1 - Ws_Alelle2) and the P-value (P-value ratio = P-value_Allele1 / P-value_Allele2) of each of the alleles, position by position throughout the scanning window.

**Ws = ln( P(S|M))/P(S/B)**

where S is a sequence segment of the same length of M, M is the PSSM, and B is the background model. Hence, P(S|M) is the probability of the sequence given the PSSM and P(S|B) is the probability of the sequence given the background model.





```{r rsat_rest_api_R}



if (parameters$RSAT.rest) {
  
  #### RSAT variation-info ####
  
  # Create the vector of SOIs
  SOI.string <- paste(collapse = ",", SOIs$refsnp_id)
  # SOI.string <- paste(collapse = ",", SOIs$refsnp_id[1:100]) # FOR DEBUGGING
  
  ## Submit a query to variation-info via the REST interface
  message("\tRetrieving information on variants from RSAT REST Web services")
  varInfo.time <- system.time(
    varInfo <- POST(file.path(parameters$RSAT.rest.root, "variation-info", "Homo_sapiens", "GRCh38"),
                    body = list(i_string = SOI.string,
                                i_string_type = 'text'))
  )
  # View(varInfo)
  message("Time to run RSAT variation-info\n", varInfo.time)
  
  ## Extract the content from the REST response
  varInfo.content <- httr::content(varInfo, as = "text", encoding = "UTF-8")
  # class(varInfo.content)
  
  ## Parse the JSON content
  varinfo.fromJSON <- fromJSON(varInfo.content)
  # names(varinfo.fromJSON)
  varInfo.URL <- varinfo.fromJSON$result_url
  varInfo.server.path <- varinfo.fromJSON$result_path
  
  ## Download variation info result and store it to a local file
  outfiles["RSAT variation-info (varBed)"] <- file.path(
    result.dir.path["RSAT"],
    paste(sep = "", parameters$query, "_SOIs_info", ".varbed"))
  download.file(url = varInfo.URL, destfile = outfiles["RSAT variation-info (varBed)"])
  # system(paste("open", result.dir.path["RSAT"]))
  
  #### RSAT variation-seq ####s
  
  # ## Build the API request for retrieve-variation-seq and submit it
  message("\tRetrieving the sequences surrounding variants from RSAT REST Web services")
  varSeq <- POST(file.path(parameters$RSAT.rest.root, "retrieve-variation-seq", "Homo_sapiens", "GRCh38"),
                 body = list(i_string = varInfo.server.path,
                             i_string_type = 'piping'))
  
  ## Parse the content returned from the server
  varSeq.content <- httr::content(varSeq, "text", encoding = "UTF-8")
  
  ## Parse the JSON content
  varSeq.fromJSON <- fromJSON(varSeq.content)
  varSeq.server.path <- varSeq.fromJSON$result_path
  varSeq.URL <- varSeq.fromJSON$result_url
  
  ## Download variation info result and store it to a local file
  outfiles["RSAT retrieve-variation-seq (varSeq)"] <- file.path(
    result.dir.path["RSAT"],
    paste(sep = "", parameters$query, "_SOIs_seq", ".varSeq"))
  download.file(url = varSeq.URL, destfile = outfiles["RSAT retrieve-variation-seq (varSeq)"])
    # system(paste("open", result.dir.path["RSAT"]))

  #### RSAT variation-scan ####
  
  ## Build the API request for Variation-scan and submit it
  message("Scanning variant alleles with motifs via RSAT REST services")
  varscan <- POST(file.path(parameters$RSAT.rest.root, "variation-scan", "Homo_sapiens", "GRCh38"),
                  body = list(
                    i_string = varSeq.server.path,
                    i_string_type = 'piping',
                    m_string = parameters$motifDB.URL,
                    m_string_type = "url",
                    m_format =  "transfac"),
                  top = 2,
                  uth_pval = parameters$RSAT.varscan.pval,
                  lth_pval_ratio = parameters$RSAT.varscan.pval.ratio,
                  add_headers("Accept" = "application/json"))
  #                add_headers("Accept" = "text/plain"))
  
  # var <- content(varscan, "text", encoding = "UTF-8")
  # var <- fromJSON(var)
  
  
  ## Parse the content returned from the server
  varscan.content <- httr::content(varscan, "text", encoding = "UTF-8")
  
  ## Parse the JSON content
  varscan.fromJSON <- fromJSON(varscan.content)
  varscan.server.path <- varscan.fromJSON$result_path
  varscan.URL <- varscan.fromJSON$result_url
  
  ## Download variation info result and store it to a local file
  outfiles["RSAT variation-scan (tsv)"] <- file.path(
    result.dir.path["RSAT"],
    paste(sep = "", parameters$query, "_SOIs_var", ".tsv"))
  download.file(url = varscan.URL, destfile = outfiles["RSAT variation-scan (tsv)"])
  system(paste("open", result.dir.path["RSAT"]))
}

```



```{r importing_variascan_results}

## Importing variation-scan result
varscanFile <- file.path(
  result.dir.path["RSAT"],  
  paste0(parameters$query, "_varscan_web.txt"))
# system(paste("open ", varscanFile))

## Load variation-scan results
## Note: this is a temporary solution, since variation-scan should be invoked via REST Web services 
variationScan.ori <- read.delim(file =  varscanFile,
                            header = TRUE,
                            sep = "\t",
                            comment.char = ";")
# head(variationScan.ori)

# Split var_coord column
varscan <- separate(
  data = variationScan.ori,
  col = "var_coord",
  into = c("chrom", "pos_Start", "pos_End", "strand"),
  sep = "[\\:\\-_]", remove = F)


# Rename the motif ID to make it compatible with Jaspar motif IDs. 
# For some reason, in RSAT collecitons the JASPAR IDs replace the "." by "_". 
# 
# This shold actually be fixed in RSAT collections rto ensure intertoperability, 
# but in the meantime we use this substitution as a patch
varscan$X.ac_motif <- gsub(pattern = "_", ".", varscan$X.ac_motif)

## Count the number of results (SNP - motif pairs) reported by variation-scan
nbVarscanResults <- nrow(varscan)
workflowSummary["variation-scan: SNP-motif pairs returned by variation-scan"] <- nbVarscanResults

## Count the number of distinct motifs from Jaspar reported by variation-scan
varscan.nb.motifs <- length(unique(varscan$X.ac_motif))
message("Number of ref TFBM with at least one prediction in the SNPs: ", varscan.nb.motifs)
workflowSummary["variation-scan: Number of TFBM altered by the SOIs"] <- varscan.nb.motifs

## Count the number of distinct variants (SNPs) reported by variation-scan
varscan.nb.snps <- length(unique(varscan$var_id))
message("Number of SNPs detected by variation-scan: ", varscan.nb.snps)
workflowSummary["variation-scan: predicted rSNPs"] <- varscan.nb.snps
```



### Assignation of TFs from JASPAR with the corresponding motif in RSAT variation-scan

In this section, we download the Jaspar motifs identifier and  corresponding transcription factor (TF) names. We need these data for to compare and select the TF names correspending their motifs in variation-scan results.


```{r get_JASPAR_annotation}
## Define the path of the JASPAR annotation file
jaspar.annotation.file <- file.path(
  result.dir.path["JASPAR"],
  paste0("jaspar_", "CORE", "_", "vertebrates", "_matrix_annotations.tsv"))



if (file.exists(jaspar.annotation.file)) {
  message("Loading Jaspar annotation table from file\n\t", jaspar.annotation.file)
  ## Load Jaspar annotation table from file if it exists
  jaspar.annotation.table <- read.delim(jaspar.annotation.file, header = TRUE, sep = "\t")
} else {
  
  ## Collect annotations for all motifs of the JASPAR collection
  jaspar.annotation.table <- CollectJasparAnnotations(
    outdir = result.dir.path["JASPAR"], 
    # tax.group = "vertebrates",
    collection = "CORE",
    save.pssm = TRUE,
    save.logos = FALSE,
    overwrite = FALSE)
}
# View(jaspar.annotation.table)
message("Loaded Jaspar annotation table for ", nrow(jaspar.annotation.table), " motifs. ")

```


```{r merge_varscan_jaspar}

#### Merge annotation table from Jaspar with the variation-scan result table ####

## We merge the variations-can result table with Jaspar annotations in order 
## to get the information 
varscan.jaspar.merged <- merge(
  x = varscan, 
  y = jaspar.annotation.table, 
  by.x = "X.ac_motif",
  by.y = "matrix.id",
  sort = FALSE)
# dim(varscan)
# dim(jaspar.annotation.table)
# dim(varscan.jaspar.merged)
# names(varscan)
# names(jaspar.annotation.table)
# names(varscan.jaspar.merged)

# setdiff(names(variationScan), names(varscan))

varscan.jaspar.merged$label <- paste(varscan.jaspar.merged$X.ac_motif, varscan.jaspar.merged$name)

```



```{r varscan_snps_per_motif, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Distribution of TFBS potentially affected by each SOI from variation-scan results.** "), out.width = "100%", fig.width=10, fig.height=4.5}

# Barplot of the number of SNPs affected per motif
# barplot(sort(table(varscan.jaspar.merged$matrix_id), decreasing = TRUE),
SNPs.per.motif <- sort(table(varscan.jaspar.merged$label), decreasing = TRUE)

max.motifs <- min(length(SNPs.per.motif), 20)

if (max.motifs > length(SNPs.per.motif)) {
  # plot distribution of SNPs per motif for all motifs, without labels
  par(mfrow = c(1,2))  
  par(mar = c(9.1, 5.1, 4.1, 2.1))
  barplot(SNPs.per.motif,
          main = "A. variation-scan\nSNPs per motif",
          xlab = "Number of predicted rSNPs",
          ylab = "Motif rank",
          las = 2, names = 1:length(SNPs.per.motif),
          col = "#37A3F3", border = "#05245F",
          horiz = FALSE)
} else {
  par(mfrow = c(1,1)) 
}

## Plot the SNPs per motif for the top-ranking motifs only, in order to see the labels
par(mar = c(9.1, 5.1, 4.1, 2.1))
barplot(SNPs.per.motif[1:max.motifs],
        main = "B. variation-scan\nTop-ranking motifs",
        ylab = "Number of predicted rSNPs",
        xlab = NA,
        las = 2, cex.names = 0.8, 
        col = "#37A3F3", border = "#05245F",
        horiz = FALSE)
par(mar = c(5.1, 5/1, 4.1, 2.1))
par(mfrow = c(1,1))
```


```{r varscan_heatmap, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Heatmap of rSNPs predicted by variation-scan.** "), out.width = "100%", fig.width=10, fig.height=6}
#varscan.jaspar.merged$best_pval <- -log10(varscan.jaspar.merged$best_pval)


ggplot(varscan.jaspar.merged, aes(label, var_id)) + geom_tile(aes(fill = -log10(best_pval)),
     colour = "white") + 
     labs(x='Motifs', y = 'SNPs')+
      theme_bw()+
      guides(fill = guide_legend(title = "-log10(P-value)"))+
  ggtitle("Heatmap of rSNPs predicted by variation-scan") +
      #theme(legend.position="none")+
      theme(plot.title = element_text(hjust = 0.5,size = 10),axis.title = element_text(size=15))+
      theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),panel.grid.major= element_blank(),panel.grid.minor = element_blank())
```


### Distribution of variation-scan scores


```{r varscan_score_distributions, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Distributions of scores returned by variation-scan.** (**A**) Best (red) and worst (blue) p-value. (**B**) Ratio between worst (blue) and best (red) p-value ( pval_ratio = worst_pval/best_pval ). (**C**) emphazise the differences between best weigth for the putative site (red) and worst weigth for the putative site (blue). "), out.width = "100%", fig.width=8, fig.height=7}

par(mfrow = c(2,2))  
#par(mar = c(9.1, 5.1, 4.1, 2.1))

varscan.jaspar.merged$best_pval <- as.numeric(varscan.jaspar.merged$best_pval)
varscan.jaspar.merged$worst_pval <- as.numeric(varscan.jaspar.merged$worst_pval)

best.pval <- -log10(varscan.jaspar.merged$best_pval)
worst.pval <- -log10(varscan.jaspar.merged$worst_pval)

pval.range <- range(c(best.pval, worst.pval))

n <- nrow(varscan.jaspar.merged)
f <- 1:n / n
plot(sort(best.pval), f, type = "l", col = "blue", 
     xlim = pval.range,
     main = "A. P-value distributions",
     xlab = "-log10(P-value)",
     ylab = "Frequency")
lines(sort(worst.pval), f, type = "l", col = "red")
legend(1, 95, legend = c("Best P-value", "Worst P-value"),
       col = c("blue", "red"), lty = 1:2, cex = 0.8)


grid(col = "#DDDDDD", lty = "solid")

###################################################
## Plotting P-value ratio


pvalRatioPos <- log10(varscan.jaspar.merged$pval_ratio)


#pvalRatio.range <- range(c(pvalRatioPos, pvalRatioNeg))

n <- nrow(varscan.jaspar.merged)
f <- 1:n / n
plot(sort(pvalRatioPos), f, type = "l", col = "blue", 
     #xlim = pvalRatio,
     main = "B. P-value ratio distributions",
     xlab = "-log10(P-value ratio)",
     ylab = "Frequency")


grid(col = "#DDDDDD", lty = "solid")

## Weight
varscan.jaspar.merged$best_w <- as.numeric(varscan.jaspar.merged$best_w)
varscan.jaspar.merged$worst_w <- as.numeric(varscan.jaspar.merged$worst_w)

best.weight <- varscan.jaspar.merged$best_w
worst.weight <- varscan.jaspar.merged$worst_w

weight.range <- range(c(best.weight, worst.weight))


n <- nrow(varscan.jaspar.merged)
f <- 1:n / n
plot(sort(best.weight), f, type = "l", col = "blue",
     xlim = weight.range,
     main = "C. Weight distributions",
     xlab = "Weight",
     ylab = "Frequency")

lines(sort(worst.weight), f, type = "l", col = "red")

legend(2000,9.5, # places a legend at the appropriate place 
      c("best.weight", "worst.weight"))

grid(col = "#DDDDDD", lty = "solid")

#par(mar = c(5.1, 5/1, 4.1, 2.1))
par(mfrow=c(1,1))
```



## Annotation of SNPs with Chip-Seq peaks from ReMap

The ReMap catalog [@Griffon:2015en, @Cheneby:2018ix] is an integrative analysis of transcriptional regulators ChIP-seq experiments from both Public and Encode datasets [@ENCODEProjectConsortium:2012gc]. We used the `ReMapEnrich` package to identify the significant enriched region from ReMap catalog conrresponding of the TFBS altered by the potential regulatory SNPs.

The principle of the test is to measure the significance of the intersection between regions of interest and each set of ReMap peaks (a peak game for each ChIP-seq experiment in ReMap). This significance is measured with a p-value, which represents the probability of obtaining an intersection at least as important under a null hypothesis, that is, if we chose regions of the same size randomly.



```{r load_remap_data}
message("Downloading the ReMap catalog.")

## Specify the files containing bed peak catalogue in two formats`
## - bed: downloaded from ReMap
## - Rdata: exported with this script after the first loading, in order to accelerate subsequent loadins
remapBedFile <-  paste(sep = "", parameters$data.dir, "/remap2018_all_macs2_hg38_v1_2.bed.gz")

# Define the path to saving .Rda file
remapRdataFile <- file.path(parameters$data.dir,
                      paste(sep = "", "remap2018_all_macs2_hg38_v1_2", ".Rdata"))


## Load ReMap peaks from Rdata file if it is there (faster loading)
if (file.exists(remapRdataFile)) {
  message("Loading ReMap peaks from Rdata file.")
  # Load the ReMap Rdata file
  system.time({load(remapRdataFile)})
} else {

  # Downloading the ReMap peak data 
  #download.file(parameters$remapUrl, destfile = remapBedFile, method = "libcurl")
  if (file.exists(remapBedFile)) {
    message("Remap bed file already exists, skipping download. ")
    message("\t", remapBedFile)
  } else {
    message("Downloading the ReMap catalog")
    system.time({download.file(parameters$remapUrl, 
                               dest = remapBedFile, method = "libcurl") })
  }

  ## Load the bed files
  message("Loading ReMap peaks from bed file")
  system.time({remap.data <- fread(file = remapBedFile) })
  
  ## Convert the bed peaks into a grange object
  message("Converting ReMap peaks into grange objects")
  system.time({ 
    remapCatalog.gr <- with(remap.data,
                            GRanges( seqnames = Rle(V1),
                                     ranges   = IRanges(start = V2, end = V3),
                                     strand   = Rle("*"), name = V4))
  })
  
  # Save the remap data Grange format in Rda format
  message ("Saving ReMap file in Rda format")
  system.time({  save(remapCatalog.gr, file = remapRdataFile) })
}


# Compute overlaps between ReMap peaks and SNPs of interest
message("Computing intersection between ReMap peaks and SOIs")
IntersectBed <- function(a, b) {
  #library(GenomicRanges)
  my.hits <- findOverlaps(a, b, type = "any")
  my.df  <- cbind(as.data.frame(a[queryHits(my.hits)]),
                  as.data.frame(b[subjectHits(my.hits)]))
  return(my.df)
}

## Intersection between remap catalog and haplotype blocks of the SOIs 
#remap.SOI.overlaps <- data.frame(IntersectBed(remapCatalog, SOIsBed.gr))

#remap.SOI.overlaps <- data.frame(IntersectBed(remapCatalog.gr, haplotype.block.gr))
remap.SOI.overlaps <- data.frame(IntersectBed(remapCatalog.gr, SOIsBed.gr))
# dim(remap.SOI.overlaps)
# length(SOIsBed.gr)
# length(remapCatalog.gr)
nbremap.SOI.overlaps <- nrow(remap.SOI.overlaps)
message("Number of overlaps between SOIs and ReMap peaks: ", nbremap.SOI.overlaps)
workflowSummary["ReMap: overlaps between SOIs and ReMap peaks"] <- nbremap.SOI.overlaps

## Split the ReMap peakset ID in order to obtain separate columns with the
## 1. GEO series
## 2. Transcription factor name
## 3. Tissue / condition

remap.SOI.overlaps <- separate(data = remap.SOI.overlaps, col = "name", into = c("GSE", "TF", "Tissue"), sep = "\\.", remove = FALSE)

# head(remap.SOI.overlaps)

## Export SOIs file in tsv format
outfiles["SOI overlaps with peaks from ReMap (tsv)"] <- file.path(
  result.dir.path["ReMap"], 
  paste(sep = "", parameters$query, "_SOIs_ReMap_overlaps", ".tsv"))

write.table(x = remap.SOI.overlaps,
              file = outfiles["SOI overlaps with peaks from ReMap (tsv)"],
              quote = FALSE,
              sep = "\t",
              row.names = FALSE,
              col.names = TRUE)
#system(paste("open", result.dir.path["ReMap"]))


```

```{r annotate_sois_with_remap}

#### Annotate SOIs with ReMap results ####

# names(SOIs)
# dim(SOIs)

## Count the number of ReMap peaks overlapping each SOI
remap.peaks.per.SOI <- as.data.frame.table(table(remap.SOI.overlaps$rsid))
names(remap.peaks.per.SOI) <- c("refsnp_id", "ReMap.nb.peaks")
# head(peaks.per.SOI)
# head(SOIs)
SOIs.annotations <- merge(x = SOIs, 
                          y = remap.peaks.per.SOI,
                          all.x = TRUE,
                          by = "refsnp_id")

## Count the number of unique TFs whose peaks overlap each SOI 
## Beware, one ReMap TF might overlap the same SNP with several peaks, 
## if there are different datasets with this TF
## (e.g. in different tissue / cell types) 
remap.SNP.TF <- unique(remap.SOI.overlaps[, c("rsid", "TF")])
remap.nb.TFs.per.SOI <-  as.data.frame.table(table(remap.SNP.TF$rsid))
names(remap.nb.TFs.per.SOI) <- c("refsnp_id", "ReMap.nb.TFs")
# names(SOIs.annotations)
# names(remap.SNP.TF)
SOIs.annotations <- merge(x = SOIs.annotations, 
                          y = remap.nb.TFs.per.SOI,
                          all.x = TRUE,
                          by = "refsnp_id")
# View(SOIs.annotations)

## Concatenate the names of the factors whose peaks overlap each SOI
remap.TFs.per.SOI <- t(as.data.frame(as.list(
  by(data = remap.SNP.TF$TF, 
     INDICES = remap.SNP.TF$rsid, 
     FUN = paste, collapse = "; "))))
remap.TFs.per.SOI[is.na(remap.TFs.per.SOI)] <- "" ## Replace NA values by empty string
colnames(remap.TFs.per.SOI) <- "ReMap.TF.names"
# class(TFs.per.SOI)
# View(TFs.per.SOI)
# names(SOIs)
# head(TFs.per.SOI)

SOIs.annotations <- merge(x = SOIs.annotations, 
                          y = remap.TFs.per.SOI,
                          all.x = TRUE,
                          by.x = "refsnp_id", 
                          by.y = "row.names")
# View(SOIs.annotations)
# head(SOIs.annotations)

```


```{r annotate_sois_with_varscan}

#### Annotate SOIs with variation-scan results ####


## Count the number of unique TFs whose peaks overlap each SOI 
## Beware, one ReMap TF might overlap the same SNP with several peaks, 
## if there are different datasets with this TF
## (e.g. in different tissue / cell types) 
varscan.SNP.TF <- unique(varscan.jaspar.merged[, c("var_id", "name")])
names(varscan.SNP.TF) <-  c("refsnp_id", "varscan.TF")
# head(varscan.SNP.TF)
nb.varscan.TFs.per.SOI <-  as.data.frame.table(table(varscan.SNP.TF$refsnp_id))
names(nb.varscan.TFs.per.SOI) <-  c("refsnp_id", "varscan.TF.nb")
# names(SOIs.annotations)
# names(nb.varscan.TFs.per.SOI)
SOIs.annotations <- merge(x = SOIs.annotations, 
                          y = nb.varscan.TFs.per.SOI,
                          all.x = TRUE,
                          by = "refsnp_id")
## Replace NA values by 0 for the count of varscan TFs
SOIs.annotations$varscan.TF.nb <- as.vector(SOIs.annotations$varscan.TF.nb)
SOIs.annotations[is.na(SOIs.annotations$varscan.TF.nb), "varscan.TF.nb"] <- 0

# View(SOIs.annotations)

## Concatenate the names of the factors whose peaks overlap each SOI
varscan.TFs.per.SOI <- t(as.data.frame(as.list(
  by(data = varscan.SNP.TF$varscan.TF, 
     INDICES = varscan.SNP.TF$refsnp_id, 
     FUN = paste, collapse = "; "))))
varscan.TFs.per.SOI[is.na(varscan.TFs.per.SOI)] <- "" ## Replace NA values by empty string
colnames(varscan.TFs.per.SOI) <- "varscan.TFs"
# View(varscan.TFs.per.SOI)
# colnames(varscan.TFs.per.SOI)
# head(varscan.TFs.per.SOI)


SOIs.annotations <- merge(x = SOIs.annotations, 
                          y = varscan.TFs.per.SOI,
                          all.x = TRUE,
                          by.x = "refsnp_id", 
                          by.y = "row.names")
## Replace NA values by ""
SOIs.annotations$varscan.TFs <- as.vector(SOIs.annotations$varscan.TFs)
SOIs.annotations[is.na(SOIs.annotations$varscan.TFs), "varscan.TFs"] <- ""
# View(SOIs.annotations)
# head(SOIs.annotations)

```


```{r SOI_annotations_varscan_inter_remap}

#### Annotate SOIs with the TFs found by both RSAT and ReMap

#' @description Compute the intersection between two strings containing concatenated terms
#' @author Jacques van Helden
#' @param x first string
#' @param y second string
#' @param case.sensitive=TRUE if FALSE, convert x and y to uppercase in order to perform a case-insensitive comparison
#' @param split="; " separator
#' @param ... additional parameters are passed to strsplit()
#' @example
#' x <- "GATA1; MIER1; HDGF; ATF1; ZBTB7C"
#' y <- "RARA::RXRG; Mier1; Mecom; ZBTB7C; RUNX2"
#' 
#' ## Case-sensitive comparison
#' StringSplitIntersect(x, y, split = "; ", case.sensitive = TRUE)
#' 
#' #' ## Case-sensitive comparison
#' StringSplitIntersect(x, y, split = "; ", case.sensitive = FALSE)
#' @export
StringSplitIntersect <- function(x, 
                                 y, 
                                 case.sensitive = FALSE,
                                 split = "; ", 
                                 ...) {
  if (!case.sensitive) {
    x <- toupper(x)
    y <- toupper(y)
  }
  x.terms <- unlist(strsplit(x = x, split = split))
  y.terms <- unlist(strsplit(x = y, split = split))
  result <- base::intersect(x = x.terms, y = y.terms, ...)
  return(result)
}

#SOIs.annotations <- Vectorize(SOIs.annotations)
# head(SOIs.annotations)
i <- 1
SOIs.annotations$TF.names.remap.inter.varscan <- ""
for (i in 1:nrow(SOIs.annotations)) {
  common.TF <- StringSplitIntersect(
    x = SOIs.annotations$varscan.TFs[i],
    y = SOIs.annotations$ReMap.TF.names[i],
    case.sensitive = FALSE,
    split = "; "
  )
  SOIs.annotations[i, "remap.inter.varscan.nb.TFs"] <- length(common.TF)
  SOIs.annotations[i, "remap.inter.varscan.TF.names"] <- paste(common.TF, collapse = "; ")
}
# head(SOIs.annotations)
# View(SOIs.annotations)

```


```{r SOI_annotate_genes}
#### add gene information to SOI annotations ####

## Get gene features from Ensembl
#snpInfo$ensembl_gene_stable_id
# Specify the BioMart database and dataset to use.
message("Opennig a connection to bioMart")
bioMartConnection <- useMart(biomart = "ENSEMBL_MART_ENSEMBL", dataset = "hsapiens_gene_ensembl") 


## Select the Ensembl Gene IDs
SOIs.geneIDs.unique <- as.vector(sort(unique(SOIs.annotations$ensembl_gene_stable_id)))
SOIs.geneIDs.unique <- grep(pattern = "^ENSG", x = SOIs.geneIDs.unique, value = TRUE)
# length(geneIDs.unique)
nb.genes <- length(SOIs.geneIDs.unique)
message("Gettting information about ", nb.genes, " genes in Ensembl.")

## Get information about all genes
SOIs.geneInfo <- getBM(attributes = c('chromosome_name', 
                                 'start_position',
                                 'end_position',
                                 'strand',
                                 'ensembl_gene_id',
                                 'hgnc_symbol',
                                 'entrezgene_id',
#                                 'go_id', ## Yvon, je supprime go_id, car il provoque une multiplication des annotations (je suppose que c'est parce qu'un gène appartient à plusieurs classes GO)
                                 'description'), 
                  filters =  "ensembl_gene_id", 
                  values = SOIs.geneIDs.unique, 
                  mart = bioMartConnection)

# length(SOIs.geneIDs.unique)
# dim(SOIs.geneInfo)
# View(SOIs.geneInfo)
# names(SOIs.geneInfo)

# names(SOIs.annotations)
SOIs.annotations <- merge(x = SOIs.annotations, 
                          y = SOIs.geneInfo,
                          all.x = TRUE,
                          by.x = "ensembl_gene_stable_id",
                          by.y = "ensembl_gene_id")

# View(SOIs.annotations)

```


```{r export_SOI_annotations}

#### Sort the SOI annontation table #### 
message("Sorting SOI annotations by decreasing intersection between variation-scan and ReMap")

## Sort by decreasing number of TFs at the intersection between ReMap and variation-scan
SOIs.annotations <- SOIs.annotations[order(SOIs.annotations$remap.inter.varscan.nb.TFs, decreasing = TRUE),]

#### Export SOI annotations with varscan and ReMap ####
outfiles["SOI annotations with ReMap and varscan (tsv)"] <-
  file.path(
    result.dir.path["rSNPs"],
    paste(sep = "", parameters$query, "_SNPs_varscan_remap", ".tsv"))
message("Exporting SOI annotations to table\n", outfiles["SOI annotations with ReMap and varscan (tsv)"] )
write.table(x = SOIs.annotations, quote = FALSE,
            file = outfiles["SOI annotations with ReMap and varscan (tsv)"],
            sep = "\t", row.names = FALSE, col.names = TRUE)


```




```{r remapTF, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Transcription factors (TFs) enriched in ChIP-seq regions overlapping with the haplotype blocks of SNPs of interest (SOIs).** "), out.width = "80%", fig.width=8, fig.height=6}

SNPs.per.ReMap.TF <- sort(table(remap.SOI.overlaps$TF), decreasing = TRUE)

max.tf <- min(20, length(SNPs.per.ReMap.TF))
if (length(SNPs.per.ReMap.TF) > max.tf) {
  par(mfrow = c(1,2)) 
  par(mar = c(5.1, 5.1, 4.1, 1.1))
  barplot(rev(SNPs.per.ReMap.TF),
          main = "Overlaps between SNPs\nand TF peaks from ReMap" ,
          xlab = "Number of overlaps with SOIs",
          ylab = "Remap Transcription Factors",
          names = NA,
          las = 1, 
          cex.names = 0.7, 
          col = "#37A3F3", 
          border = "#05245F",
          horiz = TRUE,
          panel.first = grid()
        )
  
}

barplot(rev(SNPs.per.ReMap.TF[1:max.tf]),
        main = "Top-ranking TFs for SNP overlap",
        las = 1, 
        cex.names = 0.7, 
        col = "#37A3F3", 
        border = "#05245F",
        horiz = TRUE
)

par(mfrow = c(1,1)) 
```


### Profile of ChIP-seq peaks binding to TSS regions

We compute the profile ChIP-seq binding to TSS regions overlapped with the haplotype blocks of the SOIs. We are defined the flanking sequences around (by default) -3kb to +3kb . Then align the peaks that are mapping to these regions, we can to generate the tagMatrix.


```{r chip-seq_peak_annotation, results = FALSE, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Pieplot of genomic annotation. Annotation of the location of a given peak in terms of genomic features.** "), out.width = "80%", fig.width=8, fig.height=4.5}

# Create TxDb object contained transcript-related features of a particular hg38 human genome
txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene


## JvH (2019-07)25) : YVON, POURQUOI 3000 bp ? C'EST ENORME DU COTE DOWNSTREAM
message("Preparing the TSS regions, defined as flanking sequence of the TSS sites.")
promoter <- getPromoters(
  TxDb = txdb, 
  upstream = 3000, 
  downstream = 3000)


# BED file of SOI overlapped with the ReMap catalog
remap.SOI.bed.peak <- remap.SOI.overlaps[, c("seqnames", "start", "end")]

# Create a GRanges object of the ChIP-seq peak overlapped with the SOIs haplotype blocks.
remap.SOI.peak.gr <- with(remap.SOI.bed.peak,
                   GRanges( seqnames = Rle(seqnames),
                            ranges   = IRanges(start =  start, end =  end),
                            strand   = Rle("*")))
 
message("Creating a remap.SOI.peak matrix data..")
tagMatrix <- getTagMatrix(remap.SOI.peak.gr, windows = promoter)



# Heatmap of ChIP binding to TSS regions

#message("Plotting a heatmap of ChIP-seq binding to TSS regions..")

#tagHeatmap(tagMatrix, xlim = c(-3000, 3000), color = "blue")

# It's possible to create a heatmap of ChIP-seq binding to TSS regions using a ChIP-seq peak data in GRange format.
#peakHeatmap(remap.SOI.peak.gr, TxDb=txdb, upstream=3000, downstream=3000, color="blue")



## Compute Average Profile of ChIP peaks binding to TSS region
## Confidence interval estimated by bootstrap method 
## is also supported for characterizing ChIP binding profiles.
message("Compute the average profile of ChIP-seq peaks binding to TSS region")
plotAvgProf(tagMatrix, xlim = c(-3000, 3000),
             conf = 0.95, resample = 1000,
            xlab = "Genomic Region (5'->3')", ylab = "Read Count Frequency")

# plotAvgProf2(remap.SOI.peak.gr, TxDb=txdb, upstream=3000, downstream=3000,
#              xlab="Genomic Region (5'->3')", ylab = "Read Count Frequency")

#plotAvgProf(tagMatrix, xlim=c(-3000, 3000), conf = 0.95, resample = 1000)

```



## Regulatory SNPs analysis

The interactions between TFs and target sites are the main edges of gene regulatory networks that determines the expression levels of target genes at a particular time point during development, in a given tissue and under specific conditions.

The rSNPs alter the affinity of several TFs binding sites (TFBS). A SNP's effect on TF binding is estimated based on a position weight matrix (PWM) model for the binding specificity of the corresponding factor. 


In this section, we predict the regulatory SNPs (rSNPs) among the SOIs, as well as the TFs and  TFBS potentially affected by the variations of these rSNPs. 

To achieve this, the workflow merges the *ReMap* and *variation-scan* result tables based on  correspondences of the SNP IDS and TF names.


```{r rSNPs, out.width = "80%", fig.width=8, fig.height=4.5}

# dim(varscan.jaspar.merged)
# names(varscan.jaspar.merged)
# dim(remap.SOI.overlaps)
# names(remap.SOI.overlaps)
# varscan.jaspar.merged$var_id
# varscan.jaspar.merged$name
# remap.SOI.overlaps$rsid
# remap.SOI.overlaps$TF

## Select the intersections between rSNP predictions (variation-scan results) 
## and ChIP-seq peaks (from ReMap)
varscan.with.peaks <- merge(
  varscan.jaspar.merged, 
  remap.SOI.overlaps, 
  by.x = c("var_id", "name"),
  by.y = c("rsid", "TF"))

# View(varscan.with.peaks)

#kable(head(varscan.with.peaks[, c( "chrom","pos_Start", "var_id", "X.ac_motif", "name", "best_pval", "pval_ratio")]), caption = "Potential regulatory SNPs ")

## Count the number of rSNPs, i.e. those where the variation-scan prediction matches a ChIP-seq peak annotated in ReMap.
nbrSNPs <- length(unique(varscan.with.peaks$var_id))
workflowSummary["rSNPs: predicted potential rSNPs"] <- nbrSNPs
message("Number of rSNPs: ", nbrSNPs)


## Count the number of transcription factors whose binding is confirmed by ReMap and predicted by variation-scan to be affected by some SOI
nb.TFs <- length(unique(varscan.with.peaks$name))
workflowSummary["TFs: TFs whose the TFBS are affected by the rSNPs"] <- nb.TFs
message("Number of TFs: ", nb.TFs)



## Export the rSNPs file in tsv format
outfiles["candidate rSNPs"] <- file.path(
  result.dir.path["rSNPs"], 
  paste(sep = "", parameters$query, "_rSNPs", ".tsv"))

write.table(x = varscan.with.peaks,
              file = outfiles["candidate rSNPs"],
              quote = FALSE,
              sep = "\t",
              row.names = FALSE,
              col.names = TRUE)
# system(paste("open", result.dir.path["rSNPs"]))

```


```{r gene_info}

#### Get gene features from Ensembl ####
#snpInfo$ensembl_gene_stable_id
# Specify the BioMart database and dataset to use.
bioMartConnection <- useMart(biomart = "ENSEMBL_MART_ENSEMBL", dataset = "hsapiens_gene_ensembl") 

# JvH 209-07-27: YVON, plutôt que de collecter geneInfo avec le vecteur redondant des gènes associés à chaque SNP, puis de filtrer les valeurs uniques, il me semble plus logique de lancer la requête geneInfo <- getBM avec un vecteur de valeurs uniques pour les IDs ensembl de gènes.

## Select the Ensembl Gene IDs
rSNPs.geneIDs.unique <- as.vector(sort(unique(snpInfo$ensembl_gene_stable_id)))
rSNPs.geneIDs.unique <- grep(pattern = "^ENSG", x = rSNPs.geneIDs.unique, value = TRUE)
# length(rSNPs.geneIDs.unique)
nb.genes <- length(rSNPs.geneIDs.unique)
message("Gettting information about ", nb.genes, " genes in Ensembl.")

## Get information about all genes
geneInfo <- getBM(attributes = c('chromosome_name', 
                                 'start_position',
                                 'end_position',
                                 'ensembl_gene_id',
                                 'hgnc_symbol',
                                 'entrezgene_id',
#                                 'go_id', ## Yvon, je supprime go_id, car il provoque une multiplication des annotations (je suppose que c'est parce qu'un gène appartient à plusieurs classes GO)
                                 'description'), 
                  filters =  "ensembl_gene_id", 
                  values = rSNPs.geneIDs.unique, 
                  mart = bioMartConnection)

#length(rSNPs.geneIDs.unique)
# dim(geneInfo)
# View(geneInfo)
# names(geneInfo)


# Remove duplicated genes
geneInfo.uniq <- geneInfo[!duplicated(geneInfo$ensembl_gene_id),]
# dim(geneInfo.uniq)
# View(geneInfo.uniq)

# Merging snpInfo and geneInfo data tables
snpInfo.with.geneInfo <- merge(x = snpInfo,
                             y = geneInfo.uniq,
                             by.x = "ensembl_gene_stable_id",
                             by.y = "ensembl_gene_id", 
                             all.x = TRUE)
# dim(snpInfo)
# dim(snpInfo.with.geneInfo)
# View(snpInfo.with.geneInfo)

# Merging gene and SNPs informations with the rSNP table
rSNPs.info <- merge(varscan.with.peaks,
                    snpInfo.with.geneInfo,
                    by.x = "var_id",
                    by.y = "refsnp_id",
                    all.x = TRUE,
                    all.y = FALSE)


rSNPs.info.display <- rSNPs.info[, c("chrom", "hgnc_symbol",  "var_id", "pos_Start", "var_class", "best_variant", "worst_variant" , "best_pval", "pval_ratio", "X.ac_motif", "name",  "consequence_type_tv")]

kable(head(rSNPs.info.display), caption = "Predicted regulatory SNPs")


```


### Peak annotation 

We using `ChIPseeker` R package to annotate the ChIP-seq peaks co-localised with the rSNPs. We presente the genomic annotations of the ChIP-seq paeks co-localised with the rSNPs

```{r peak_annotation_rSNPs, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Pieplot of genomic annotation. Annotation of the location of a given peak in terms of genomic features.** "), out.width = "80%", fig.width=8, fig.height=4.5}

if (nrow(rSNPs.info) == 0) {
  message("The merging between RSAT variation-scan and ReMap ChIP-seq peaks did not return a single predicted rSNP. Skipping peak annotations. ")
  
} else {

  
  # Create a bed file for rSNPs overlaped with ChIP-seq peaks
  rSNPs.bed <- rSNPs.info[, c("seqnames", "start", "end")]
  
  
  # Create a GRanges object for rSNPs overlaped with ChIP-seq peaks
  rSNPs.gr <- with(rSNPs.bed,
                   GRanges( seqnames = Rle(seqnames),
                            ranges   = IRanges(start =  start, end =  end),
                            strand   = Rle("*")))
  
  message("Running peak annotation with peakAnno.")
  
  ## The TSS regions of 3kb is not restricted to TSS regions. The regions 
  ## can be other types that defined by the user.
  
  
  peakAnno <- annotatePeak(rSNPs.gr, tssRegion = c(-3000, 3000),
                           TxDb = txdb, annoDb = "org.Hs.eg.db")
  
  # print(peakAnno)
  
  #plotAnnoBar(peakAnno1)
  plotAnnoPie(peakAnno, 
              legend.position = "rightside", 
              ndigit = 0.5, 
              cex = 0.1,
              col = NA,
              pie3D = FALSE)
  
  #vennpie(peakAnno1, r = 0.2)
  
  # Distribution of TF-binding loci relative to TSS
  # Percentage of binding sites upstream and downstream from the TSS of the nearest genes
  #plotDistToTSS(peakAnno, title = "Distribution of TF-binding loci \n relative to TSS")
}

```



```{r varscan_results, out.width = "100%", fig.width=8, fig.height=4, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Heatmap of the scanning of the SOIs with motifs using *variation-scan*.** **A. ** P-value of the best putative site. **B. **  Ratio between worst and best P-value. ")}

if (nrow(rSNPs.info) == 0) {
  message("The merging between RSAT variation-scan and ReMap ChIP-seq peaks did not return a single predicted rSNP. Skipping figure. ")
  
} else {
  
  ## rSNPs with hight effect of motif alteration
  motif.alt.effect <- varscan.with.peaks %>% 
    dplyr::select(var_id, label, best_pval) 
  #dplyr::group_by() %>% 
  #dplyr::summarise(N = n()) 
  motif.alt.effect$best_pval = -log10(motif.alt.effect$best_pval)
  
  
  A <- ggplot(motif.alt.effect, aes(label, var_id)) + geom_tile(aes(fill = best_pval),
                                                                colour = "white") + scale_fill_gradient(low = "white",
                                                                                                        high = "steelblue")+
    labs(x='', y = '')+
    theme_bw()+
    guides(fill = guide_legend(title = "-log10(P-value)"))+
    ggtitle("rSNPs with hight effect of motif alteration") +
    #theme(legend.position="none")+
    theme(plot.title = element_text(hjust = 0.5,size = 10),
          axis.title = element_text(size=10),
          legend.title = element_text(size=10),
          legend.text = element_text(size=8))+
    theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),panel.grid.major= element_blank(),panel.grid.minor = element_blank())
  
  
  
  motif.alt.pv_ratio <- varscan.with.peaks %>% 
    dplyr::select(var_id, label, pval_ratio) 
  #dplyr::group_by() %>% 
  #dplyr::summarise(N = n()) 
  
  B <- ggplot(motif.alt.pv_ratio, aes(label, var_id)) + geom_tile(aes(fill = pval_ratio),
                                                                  colour = "white") + scale_fill_gradient(low = "#145A32",
                                                                                                          high = "#37A3F3")+
    labs(x='', y = '')+
    theme_bw()+
    guides(fill = guide_legend(title = "Pval-ratio"))+
    #ggtitle("rSNPs with hight effect of motif alteration") +
    #theme(legend.position="none")+
    theme(plot.title = element_text(hjust = 0.5,size = 10),
          axis.title = element_text(size=10),
          legend.title = element_text(size=10),
          legend.text = element_text(size=8))+
    theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),panel.grid.major= element_blank(),panel.grid.minor = element_blank())
  
  plot_grid(A, B,  labels=c("A", "B"), ncol = 2, nrow = 1)
}

```




```{r download_logos_from_jaspar}
### Visualization of TFBS in logos
## Adapted from: <Aziz Khan>aziz.khan@ncmm.uio.no

#set path to store results
# dir.create(paste0(result.dir.path["JASPAR"],'logo'), showWarnings = FALSE, recursive = TRUE)
# 
# #get human profiles
# url <- paste0(parameters$jaspar.rest.root,"matrix/?collection=CORE&tax_group=vertebrates&order=name&version=latest&page_size=1000&format=json")
# result <- fromJSON(url)
# 
# #jaspar2018_pubmedid = "29140473"
# 
# # Initialize a vector
# results_matrix = c()
# matrix_ids = result$results$matrix_id
# 
# # Create the vector of matrix_id from variation-scan
# rSNPsMatrix <- varscan.with.peaks$matrix_id
# 
# inter.matrix_ids <- intersect.Vector(rSNPsMatrix, matrix_ids)
# 
# for (matrix_id in inter.matrix_ids)
# {
#   matrix_url <- paste0(parameters$jaspar.rest.root,"matrix/", matrix_id,".json")
#   matrix_result <- fromJSON(matrix_url)
#   message(paste0("Downloading...", matrix_result$sequence_logo))
#   
#   source <- matrix_result$source;
#   if(is.null(source)){
#     source = 'NA';
#   }
# 
# # Downloag and save logo
# logo_url <- matrix_result$sequence_logo
# logo_file = paste0(result.dir.path["JASPAR"], 'logo/', matrix_result$matrix_id, ".svg")
# 
# download.file(logo_url, destfile = logo_file, method = "libcurl")
# }

```



```{r grImport2_import_svg, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Logos for TFBSM affected by the rSNPs.** "), out.width = "80%", fig.width=8, fig.height=4.5}
## We used the `grImport2` package for R imports the TFBSM SVG images directly into R.

# logoDir <- paste0("~/cisreg-GWAS_results/", parameters$query, "/JASPARlogo/")
# 
# logoList <- list.files(path = logoDir, 
#                        pattern = ".svg", 
#                        all.files = T, 
#                        full.names = F, 
#                        no.. = T) 
# if (length(logoList) == 0) {
#   message("No logo in the logo dir: ", logoDir)
# } else {
#   firstLogo <- readPicture(file.path(logoDir, logoList[1]))
#   grid.picture(firstLogo)
# }

```



```{r rsnp_tf_gene_tissue, out.width = "100%", fig.width=8, fig.height=7, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". **A. ** Predicted rSNPs and the corresponding TFs whose DNA binding sites are affected. **B. **Predicted TFs across representative tissue/cell types as reported by ReMap catalog. **C. ** rSNPs and associated genes.**")}

## rSNPs and associated TFs
if (nrow(varscan.with.peaks) == 0) {
  message("Skipping TF/tissue figure because the merging between RSAT variation-scan and ReMap did not return a single rSNP. ")
} else {
  snp.tf <- varscan.with.peaks %>% 
    dplyr::select(label, var_id) %>% 
    dplyr::group_by(var_id, label) %>% 
    dplyr::summarise(N = n()) 
  
  A <- ggplot(snp.tf, aes(label, var_id)) + geom_tile(aes(fill = N)) +
    labs(x='TFs', y = 'rSNPs') +
    theme_bw()+
    guides(fill = guide_legend(title = "TFs"))+
    #guides(fill = TRUE) +
    #ggtitle("") +
    #theme(legend.position="none")+
    theme(plot.title = element_text(hjust = 0.5,size = 10),axis.title = element_text(size=10))+
    theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),panel.grid.major= element_blank(),panel.grid.minor = element_blank())
  
  
  ## TF and tissue
  tissue <- varscan.with.peaks %>% 
    dplyr::select(name, Tissue) %>% 
    dplyr::group_by(Tissue, name) %>% 
    dplyr::summarise(N = n()) 
  
  tissue$N <- sort(tissue$N, decreasing = F)
  
  B <- ggplot(data=tissue, aes(x=Tissue, y=N, fill=name)) +
    geom_bar(stat="identity", position=position_dodge(), color="black") +
    theme_bw() +
    labs(x='Tissue', y = 'Frequency')+
    guides(fill = guide_legend(title = "TFs"))+
    theme(legend.title = element_text(size=10),
          legend.text = element_text(size=8))+
    #ggtitle("Predicted TFs in the corresponding tissue/cell type") +
    coord_flip() +
    #theme(legend.position="none")+
    theme(plot.title = element_text(hjust = 0.5,size = 10),
          axis.title = element_text(size=10))+
    theme(axis.text.x = element_text(angle = 0, 
                                     vjust = 1, 
                                     hjust = 1, 
                                     size = 5),
          axis.text.y = element_text(size=5),
          panel.grid.major= element_blank(),
          panel.grid.minor = element_blank())
  
  
  # rSNPs and associated genes
  gene.ass <- rSNPs.info %>% 
    dplyr::select(hgnc_symbol, var_id) %>% 
    dplyr::group_by(hgnc_symbol, var_id) %>% 
    dplyr::summarise(N = n()) 
  
  C <- ggplot(gene.ass, aes(hgnc_symbol, var_id)) + 
    geom_tile(aes(fill = var_id)) +
    labs(x='Genes', y = 'rSNPs') +
    theme_bw()+
    guides(fill = FALSE) +
    #ggtitle("rSNPs and associated genes") +
    #theme(legend.position="none")+
    theme(plot.title = element_text(hjust = 0.5, size = 10),axis.title = element_text(size=10))+
    theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1),panel.grid.major= element_blank(),panel.grid.minor = element_blank())
  
  
  plot_grid(A, B, C,  labels=c("A", "B", "C"), ncol = 2, nrow = 2)
}

```




### Functional enrichment analysis 

We performe the functional enrichment analysis to identify predominant biological themes among the genes associated with the rSNPs (Gene Of Interest, GOI) by incorporating biological knowledge provided by biological ontologies.


```{r functional_analysis_rSNPs, results=FALSE, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Functional enrichment analysis of the gene in reactome biological pathway. This is a subset of most enrichissed terms. The p.adjust represent the enriched score and the number of gene by dot size.** "), out.width = "80%", fig.width=8, fig.height=4.5}

if (nrow(rSNPs.info) == 0) {
  message("The merging between RSAT variation-scan and ReMap ChIP-seq peaks did not return a single predicted rSNP. Skipping gene annotation ")
  
} else {
  
  rSNPs.gene.bed <- rSNPs.info[, c("seqnames", "start.1", "end.1")]
  
  rSNPs.gene.gr <- with(rSNPs.gene.bed,
                        GRanges( seqnames = Rle(seqnames),
                                 ranges   = IRanges(start =  start.1, end =  end.1),
                                 strand   = Rle("*")))
  
  geneAnno <- annotatePeak(rSNPs.gene.gr, #tssRegion=c(-3000, 3000),
                           TxDb=txdb, annoDb="org.Hs.eg.db")
  
  print(geneAnno)
  
  result <- try({
    gene <- seq2gene(rSNPs.gene.gr, 
                     tssRegion = c(-1000, 1000), 
                     flankDistance = 3000, 
                     TxDb = txdb);
    pathway2 <- enrichPathway(gene);
    head(pathway2, 2);
    dotplot(pathway2)
  })
  
}

```


We compute the enrichment of gene-disease associations with DisGeNET (Janet et al. 2015) from several public data sources and the literature. DisGeNET contains also gene-disease associations and SNP-gene-disease associations.

```{r gene_enrich, results=FALSE, out.width = "80%", fig.width=8, fig.height=4.5, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Top 30 significant enriched terms of functional enrichment of the genes of interest (GOI) using enrichment gene-disease associations of DisGeNET (Janet et al. 2015)**. Visualize of the enriched terms. The P-value adjested represent the enrichment scores and gene count or ratio as bar height and color.")}
if (nrow(rSNPs.info) == 0) {
  message("The merging between RSAT variation-scan and ReMap ChIP-seq peaks did not return a single predicted rSNP. Skipping enrichDGN() ")
  
} else {
  
  # Select the GOI
  geneList <- na.omit(rSNPs.info$entrezgene_id)
  
  ## Checking the enrichment gene-disease associations in DisGeNET
  edo <- enrichDGN(geneList, pvalueCutoff = 0.05, pAdjustMethod = "fdr")
  
  ## Barplot of enrichment gene-disease associations from DisGeNET
  barplot(edo)
}

```



```{r results=FALSE, circular_network, out.width = "80%", fig.width=8, fig.height=4.5, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Gene-concept network of the significant terms**. This circular network represents the potential biological complexities in which a gene may belong to multiple annotation categories.")}

if (nrow(rSNPs.info) == 0) {
  message("The merging between RSAT variation-scan and ReMap ChIP-seq peaks did not return a single predicted rSNP. Skipping cnetplot() ")
  
} else {
  
  ## convert gene ID to Symbol
  edox <- setReadable(edo, 'org.Hs.eg.db', 'ENTREZID')
  
  
  ## Circular network of the linkages of genes and biological concepts
  
  cnetplot(edox, foldChange=geneList, circular = TRUE, colorEdge = TRUE)
}

```



```{r results=FALSE, emaplot,  out.width = "80%", fig.width=8, fig.height=4.5, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Enrichment map of terms into a network with edges connecting overlapping gene sets.**")}
if (nrow(rSNPs.info) == 0) {
  message("The merging between RSAT variation-scan and ReMap ChIP-seq peaks did not return a single predicted rSNP. Skipping emapplot() ")
  
} else {
  emapplot(edo)
}
```


```{r results=FALSE, heatmap_expression_patterns, out.width = "80%", fig.width=8, fig.height=4.5, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Heatmap of expression patterns of genes of interest (GOI) and enriched terms.**")}
if (nrow(rSNPs.info) == 0) {
  message("The merging between RSAT variation-scan and ReMap ChIP-seq peaks did not return a single predicted rSNP. Skipping heatplot() ")
  
} else {
  heatplot(edox, foldChange=geneList)
}

```


### Exploring tissue-specific gene enrichment results

The below bar charts shown the tissue-specific gene enrichment.

```{r tissue_specific_gene_enrichment, results=FALSE, out.width = "80%", fig.width=8, fig.height=4.5, fig.cap=paste(sep="", "**Figure ",(fig.nb <- fig.nb +1),". Tissue-specific gene enrichment.** The x-axis shows each of the tissues, and the y-axis represents the tissue-specific gene enrichment (−Log10(P−Value)) values. ")}

if (nrow(rSNPs.info) == 0) {
  message("The merging between RSAT variation-scan and ReMap ChIP-seq peaks did not return a single predicted rSNP. Skipping tissue-specific gene enrichment. ")
    
  } else {
    # Select the associated genes with the rSNPs
  inputGenes <- unique(na.omit(rSNPs.info$hgnc_symbol))
  gs <- GeneSet(geneIds = inputGenes, organism = "Homo Sapiens", 
                geneIdType=SymbolIdentifier())
  output <- teEnrichment(inputGenes = gs)
  
  seEnrichmentOutput <- output[[1]]
  enrichmentOutput <- setNames(data.frame(assay(seEnrichmentOutput),row.names = rowData(seEnrichmentOutput)[,1]), colData(seEnrichmentOutput)[,1])
  enrichmentOutput$Tissue <- row.names(enrichmentOutput)
  
  
  ggplot(enrichmentOutput,
         aes(x=reorder(Tissue,-Log10PValue),
             y=Log10PValue,
             label = Tissue.Specific.Genes,
             fill = Tissue))+
    geom_bar(stat = 'identity')+
    labs(x='', y = '-LOG10(P-Adjusted)')+
    theme_bw()+
    theme(legend.position="none")+
    theme(plot.title = element_text(hjust = 0.5,size = 20),
          axis.title = element_text(size=15))+
    theme(axis.text.x = element_text(angle = 45, 
                                     vjust = 1, hjust = 1),
          panel.grid.major= element_blank(),
          panel.grid.minor = element_blank())
}

```




## Output files

```{r output_files}

kable(as.data.frame(outfiles), caption = "Output files.",
      col.names = "File path")

```


## Libraries and versions

```{r session_info}
session_info()

```



```{r end_time}
# End time
# end.time <- Sys.time()
# time100.2 <- round(end.time - start.time,2)
# print(round(end.time - start.time,2))

proc.time() - ptm
```





## References
